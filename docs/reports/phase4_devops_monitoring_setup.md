# Phase 4 DevOpsç›£è¦–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Ÿè£…è¨ˆç”»

## ğŸ¯ æ¦‚è¦

Phase 4ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç’°å¢ƒã®é‹ç”¨å“è³ªå‘ä¸Šã®ãŸã‚ã€åŒ…æ‹¬çš„ãªç›£è¦–ãƒ»è¦³æ¸¬æ€§ã‚¹ã‚¿ãƒƒã‚¯ã®å®Ÿè£…è¨ˆç”»ã§ã™ã€‚

## ğŸ“Š å®Ÿè£…å„ªå…ˆåº¦

### ğŸ”´ Tier 1ï¼ˆå³åº§å®Ÿè£…å¿…é ˆï¼‰
1. **ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: Prometheus + Grafana
2. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç›£è¦–**: Tursoæ¥ç¶šãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
3. **åŸºæœ¬ã‚¢ãƒ©ãƒ¼ãƒˆ**: ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ã€ã‚¨ãƒ©ãƒ¼ç‡æ€¥å¢—
4. **ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯**: å¤šå±¤ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè£…

### ğŸŸ¡ Tier 2ï¼ˆ2é€±é–“ä»¥å†…ï¼‰
1. **LLMç›£è¦–**: LangFuseçµ±åˆ
2. **ãƒ­ã‚°é›†ç´„**: æ§‹é€ åŒ–ãƒ­ã‚° + Loki
3. **SLI/SLOå®šç¾©**: å¯ç”¨æ€§ãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“
4. **ã‚³ã‚¹ãƒˆç›£è¦–**: LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ä½¿ç”¨é‡

### ğŸŸ¢ Tier 3ï¼ˆ1ãƒ¶æœˆä»¥å†…ï¼‰
1. **åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°**: OpenTelemetry
2. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–**: ç•°å¸¸æ¤œçŸ¥
3. **äºˆæ¸¬ã‚¢ãƒ©ãƒ¼ãƒˆ**: å®¹é‡ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬

## ğŸ—ï¸ æŠ€è¡“å®Ÿè£…

### Prometheusè¨­å®š
```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: autoforge-nexus
    environment: ${ENVIRONMENT}

rule_files:
  - "rules/*.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # FastAPI ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  - job_name: 'autoforge-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # Redis ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']

  # Node.js ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  - job_name: 'autoforge-frontend'
    static_configs:
      - targets: ['frontend:3000']
    metrics_path: '/api/metrics'
```

### Grafana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
```json
{
  "dashboard": {
    "title": "AutoForgeNexus - Phase 4 Database Operations",
    "panels": [
      {
        "title": "Database Connection Pool",
        "type": "graph",
        "targets": [
          {
            "expr": "sqlalchemy_pool_size{instance=\"backend:8000\"}",
            "legendFormat": "Pool Size"
          },
          {
            "expr": "sqlalchemy_pool_checked_out{instance=\"backend:8000\"}",
            "legendFormat": "Active Connections"
          }
        ]
      },
      {
        "title": "API Response Times (P95)",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, http_request_duration_seconds_bucket{job=\"autoforge-backend\"})",
            "legendFormat": "P95 Response Time"
          }
        ]
      },
      {
        "title": "Turso Query Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "turso_query_duration_seconds{quantile=\"0.95\"}",
            "legendFormat": "P95 Query Time"
          }
        ]
      }
    ]
  }
}
```

### ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«
```yaml
# monitoring/rules/database.yml
groups:
  - name: database.rules
    rules:
      - alert: DatabaseConnectionHigh
        expr: sqlalchemy_pool_checked_out / sqlalchemy_pool_size > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Database connection pool utilization high"
          description: "Connection pool is {{ $value | humanizePercentage }} full"

      - alert: DatabaseQuerySlow
        expr: histogram_quantile(0.95, turso_query_duration_seconds_bucket) > 1.0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Database queries are slow"
          description: "P95 query time is {{ $value }}s"

      - alert: APIResponseSlow
        expr: histogram_quantile(0.95, http_request_duration_seconds_bucket{job="autoforge-backend"}) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "API response time degraded"
          description: "P95 response time is {{ $value }}s"
```

## ğŸ”§ å®Ÿè£…æ‰‹é †

### Step 1: åŸºæœ¬ç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯
```bash
# 1. ç›£è¦–è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
mkdir -p monitoring/{prometheus,grafana,alertmanager}

# 2. Docker Composeç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯
docker-compose -f docker-compose.monitoring.yml up -d

# 3. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å°å…¥
curl -X POST http://grafana:3000/api/dashboards/db \
  -H "Content-Type: application/json" \
  -d @monitoring/grafana/autoforge-dashboard.json
```

### Step 2: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–
```python
# backend/src/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_LATENCY = Histogram('http_request_duration_seconds', 'HTTP request latency')
DB_CONNECTIONS = Gauge('db_connections_active', 'Active database connections')

class MonitoringMiddleware:
    async def __call__(self, request, call_next):
        start_time = time.time()

        response = await call_next(request)

        REQUEST_COUNT.labels(
            method=request.method,
            endpoint=request.url.path,
            status=response.status_code
        ).inc()

        REQUEST_LATENCY.observe(time.time() - start_time)

        return response
```

### Step 3: SLI/SLOå®šç¾©
```yaml
# monitoring/slos.yml
objectives:
  availability:
    target: 99.9%
    measurement: "sum(rate(http_requests_total{status!~'5..'}[5m])) / sum(rate(http_requests_total[5m]))"

  latency:
    target: 95%  # 95%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒ500msä»¥ä¸‹
    measurement: "histogram_quantile(0.95, http_request_duration_seconds_bucket) < 0.5"

  database_performance:
    target: 99%   # 99%ã®ã‚¯ã‚¨ãƒªãŒ1ç§’ä»¥ä¸‹
    measurement: "histogram_quantile(0.99, turso_query_duration_seconds_bucket) < 1.0"
```

## ğŸ“± ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥

### Discordçµ±åˆ
```python
# monitoring/alerting/discord_webhook.py
import httpx
import json

async def send_alert(webhook_url: str, alert_data: dict):
    embed = {
        "title": f"ğŸš¨ {alert_data['alertname']}",
        "description": alert_data.get('description', ''),
        "color": 15158332,  # Red
        "fields": [
            {"name": "Environment", "value": alert_data.get('environment'), "inline": True},
            {"name": "Severity", "value": alert_data.get('severity'), "inline": True},
            {"name": "Instance", "value": alert_data.get('instance'), "inline": True}
        ],
        "timestamp": alert_data.get('timestamp')
    }

    payload = {"embeds": [embed]}

    async with httpx.AsyncClient() as client:
        await client.post(webhook_url, json=payload)
```

## ğŸ¯ é‹ç”¨æ‰‹é †

### ãƒ‡ã‚¤ãƒªãƒ¼ãƒã‚§ãƒƒã‚¯
```bash
#!/bin/bash
# scripts/daily_health_check.sh

echo "=== AutoForgeNexus Daily Health Check ==="

# 1. ã‚µãƒ¼ãƒ“ã‚¹ç¨¼åƒçŠ¶æ³
curl -f http://localhost:8000/health || echo "âŒ Backend down"
curl -f http://localhost:3000 || echo "âŒ Frontend down"

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
python -c "from sqlalchemy import create_engine; engine = create_engine('$DATABASE_URL'); engine.connect()" || echo "âŒ DB connection failed"

# 3. RedisçŠ¶æ³
redis-cli ping || echo "âŒ Redis down"

# 4. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèª
curl -f http://localhost:9090/-/healthy || echo "âŒ Prometheus down"
curl -f http://localhost:3001/api/health || echo "âŒ Grafana down"

echo "=== Health Check Complete ==="
```

### ã‚¦ã‚£ãƒ¼ã‚¯ãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
```python
# scripts/weekly_report.py
import asyncio
from datetime import datetime, timedelta

async def generate_weekly_report():
    # SLIé”æˆç‡è¨ˆç®—
    availability = await get_metric_value("availability_sli")
    latency_p95 = await get_metric_value("latency_p95")

    report = f"""
    ## Weekly SLI Report - {datetime.now().strftime('%Y-W%U')}

    ### Availability
    - Target: 99.9%
    - Actual: {availability:.2%}
    - Status: {'âœ… Met' if availability >= 0.999 else 'âŒ Missed'}

    ### Performance
    - P95 Latency Target: <500ms
    - Actual: {latency_p95:.0f}ms
    - Status: {'âœ… Met' if latency_p95 < 500 else 'âŒ Missed'}
    """

    # Discordé€šçŸ¥
    await send_weekly_report(report)
```

## ğŸ’° ã‚³ã‚¹ãƒˆæœ€é©åŒ–

### ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
```yaml
# Cloudflare Workersä½¿ç”¨é‡ç›£è¦–
cloudflare_workers_requests_total:
  target: <100,000/day
  alert_threshold: 80,000/day

# Tursoä½¿ç”¨é‡ç›£è¦–
turso_rows_read_total:
  target: <1M/day
  alert_threshold: 800K/day
```

## ğŸ“ˆ ç¶™ç¶šæ”¹å–„

### ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã®æ‹¡å¼µ
1. **ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆæ•°ã€è©•ä¾¡å®Ÿè¡Œæ•°
2. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹**: Core Web Vitalsã€ã‚¨ãƒ©ãƒ¼ç‡
3. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: èªè¨¼å¤±æ•—ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™é”æˆ
4. **ã‚³ã‚¹ãƒˆ**: LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ä½¿ç”¨é‡ã€Cloudflareä½¿ç”¨é‡