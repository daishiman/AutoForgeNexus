# Phase 4 Infrastructure as Codeå®Ÿè£…è¨ˆç”»

## ğŸ¯ ç›®æ¨™

æ‰‹å‹•ç®¡ç†ã‹ã‚‰ã‚³ãƒ¼ãƒ‰åŒ–ã•ã‚ŒãŸå†ç¾å¯èƒ½ãªã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†ã¸ã®ç§»è¡Œã§ã€é‹ç”¨å“è³ªã¨ä¿¡é ¼æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚

## ğŸ—ï¸ Terraformå®Ÿè£…æˆ¦ç•¥

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
```
infrastructure/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â””â”€â”€ prod/
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â””â”€â”€ terraform.tfvars
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ cloudflare/
â”‚   â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ dns/
â”‚   â”œâ”€â”€ turso/
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ replicas/
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â””â”€â”€ prometheus/
â”‚   â””â”€â”€ security/
â”‚       â”œâ”€â”€ waf/
â”‚       â””â”€â”€ rate_limiting/
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ providers.tf
â”‚   â”œâ”€â”€ versions.tf
â”‚   â””â”€â”€ remote_state.tf
â””â”€â”€ scripts/
    â”œâ”€â”€ init.sh
    â”œâ”€â”€ plan.sh
    â””â”€â”€ apply.sh
```

## ğŸ”§ ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè£…

### Cloudflare Workers ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
```hcl
# modules/cloudflare/workers/main.tf
terraform {
  required_providers {
    cloudflare = {
      source  = "cloudflare/cloudflare"
      version = "~> 4.0"
    }
  }
}

resource "cloudflare_worker_script" "autoforge_backend" {
  account_id = var.cloudflare_account_id
  name       = "autoforge-backend-${var.environment}"
  content    = file("${path.module}/workers/backend.js")

  plain_text_binding {
    name = "ENVIRONMENT"
    text = var.environment
  }

  secret_text_binding {
    name = "TURSO_DATABASE_URL"
    text = var.turso_database_url
  }

  secret_text_binding {
    name = "TURSO_AUTH_TOKEN"
    text = var.turso_auth_token
  }

  secret_text_binding {
    name = "JWT_SECRET_KEY"
    text = var.jwt_secret_key
  }
}

resource "cloudflare_worker_route" "autoforge_backend" {
  zone_id     = var.cloudflare_zone_id
  pattern     = "${var.api_domain}/*"
  script_name = cloudflare_worker_script.autoforge_backend.name
}
```

### Turso ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
```hcl
# modules/turso/database/main.tf
terraform {
  required_providers {
    turso = {
      source  = "tursodatabase/turso"
      version = "~> 0.1"
    }
  }
}

resource "turso_database" "autoforge" {
  name = "autoforge-nexus-${var.environment}"

  # æœ¬ç•ªç’°å¢ƒã®ã¿ãƒ¬ãƒ—ãƒªã‚«ã‚’ä½œæˆ
  locations = var.environment == "production" ? [
    "nrt", # Tokyo
    "sin", # Singapore
    "fra"  # Frankfurt
  ] : ["nrt"]

  tags = {
    Environment = var.environment
    Project     = "AutoForgeNexus"
    Purpose     = "Primary Database"
  }
}

resource "turso_database_token" "app_token" {
  database_id = turso_database.autoforge.id

  permissions = {
    read_attach = {
      databases = [turso_database.autoforge.name]
    }
    write_attach = {
      databases = [turso_database.autoforge.name]
    }
  }

  expiration = "never"
}

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š
resource "turso_database_token" "backup_token" {
  database_id = turso_database.autoforge.id

  permissions = {
    read_attach = {
      databases = [turso_database.autoforge.name]
    }
  }

  expiration = "never"
}
```

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ & WAF ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
```hcl
# modules/security/waf/main.tf
resource "cloudflare_ruleset" "autoforge_waf" {
  zone_id     = var.cloudflare_zone_id
  name        = "AutoForge WAF Rules"
  description = "WAF rules for AutoForge Nexus"
  kind        = "zone"
  phase       = "http_request_firewall_custom"

  rules {
    action = "block"
    expression = "(http.request.uri.path contains \"/admin\" and cf.threat_score > 15)"
    description = "Block suspicious admin access"
  }

  rules {
    action = "challenge"
    expression = "(http.request.method eq \"POST\" and rate(5m) > 20)"
    description = "Rate limit POST requests"
  }

  rules {
    action = "block"
    expression = "(ip.geoip.country ne \"JP\" and ip.geoip.country ne \"US\" and http.request.uri.path contains \"/api/v1/admin\")"
    description = "Geo-block admin endpoints"
  }
}

resource "cloudflare_rate_limit" "api_rate_limit" {
  zone_id   = var.cloudflare_zone_id
  threshold = 60
  period    = 60

  match {
    request {
      url_pattern = "${var.api_domain}/api/v1/*"
      schemes     = ["HTTPS"]
      methods     = ["GET", "POST", "PUT", "DELETE"]
    }
  }

  action {
    mode    = "simulate" # æœ€åˆã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰
    timeout = 300
  }
}
```

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆè‡ªå‹•åŒ–

### GitHub Actionsçµ±åˆ
```yaml
# .github/workflows/terraform-apply.yml
name: Terraform Apply

on:
  push:
    branches: [main]
    paths: ['infrastructure/**']
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

jobs:
  terraform:
    name: Terraform Apply
    runs-on: ubuntu-latest

    env:
      TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
      TF_VAR_turso_api_token: ${{ secrets.TURSO_API_TOKEN }}

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      - name: ğŸ”‘ Configure AWS credentials (for remote state)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-1

      - name: ğŸ—ï¸ Terraform Init
        working-directory: infrastructure/environments/${{ github.event.inputs.environment || 'staging' }}
        run: terraform init

      - name: ğŸ“‹ Terraform Plan
        working-directory: infrastructure/environments/${{ github.event.inputs.environment || 'staging' }}
        run: |
          terraform plan -out=tfplan
          terraform show -no-color tfplan > plan-output.txt

      - name: ğŸ“ Comment Plan
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const plan = fs.readFileSync('infrastructure/environments/${{ github.event.inputs.environment || "staging" }}/plan-output.txt', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: 'ğŸ—ï¸ **Terraform Plan**\n\n```hcl\n' + plan + '\n```'
            });

      - name: ğŸš€ Terraform Apply
        if: github.ref == 'refs/heads/main'
        working-directory: infrastructure/environments/${{ github.event.inputs.environment || 'staging' }}
        run: terraform apply tfplan

      - name: ğŸ“Š Update Infrastructure Inventory
        if: success()
        run: |
          terraform output -json > infrastructure-state.json
          # Send to monitoring system or inventory database
```

## ğŸ”„ ç½å®³å¾©æ—§æ‰‹é †

### è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
```hcl
# modules/backup/main.tf
resource "aws_s3_bucket" "terraform_state_backup" {
  bucket = "autoforge-terraform-state-backup"

  versioning {
    enabled = true
  }

  lifecycle_rule {
    enabled = true

    noncurrent_version_expiration {
      days = 90
    }
  }
}

resource "aws_lambda_function" "state_backup" {
  filename         = "backup_lambda.zip"
  function_name    = "terraform-state-backup"
  role            = aws_iam_role.lambda_role.arn
  handler         = "index.handler"
  source_code_hash = filebase64sha256("backup_lambda.zip")
  runtime         = "python3.11"

  environment {
    variables = {
      SOURCE_BUCKET = "autoforge-terraform-state"
      BACKUP_BUCKET = aws_s3_bucket.terraform_state_backup.bucket
    }
  }
}

resource "aws_cloudwatch_event_rule" "daily_backup" {
  name                = "terraform-state-daily-backup"
  description         = "Daily backup of Terraform state"
  schedule_expression = "cron(0 3 * * ? *)"  # æ¯æ—¥3æ™‚
}

resource "aws_cloudwatch_event_target" "lambda_target" {
  rule      = aws_cloudwatch_event_rule.daily_backup.name
  target_id = "TerraformStateBackupTarget"
  arn       = aws_lambda_function.state_backup.arn
}
```

### å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# scripts/disaster_recovery.sh

set -e

ENVIRONMENT=${1:-staging}
BACKUP_DATE=${2:-$(date -d "yesterday" +%Y-%m-%d)}

echo "ğŸš¨ Starting disaster recovery for $ENVIRONMENT environment"
echo "ğŸ“… Using backup from $BACKUP_DATE"

# 1. Stateå¾©æ—§
echo "ğŸ“ Restoring Terraform state..."
aws s3 cp s3://autoforge-terraform-state-backup/$ENVIRONMENT/$BACKUP_DATE/terraform.tfstate \
  s3://autoforge-terraform-state/$ENVIRONMENT/terraform.tfstate

# 2. ã‚¤ãƒ³ãƒ•ãƒ©å†ä½œæˆ
echo "ğŸ—ï¸ Rebuilding infrastructure..."
cd infrastructure/environments/$ENVIRONMENT
terraform init
terraform plan -target=module.database
terraform apply -target=module.database -auto-approve

# 3. ãƒ‡ãƒ¼ã‚¿å¾©æ—§
echo "ğŸ—„ï¸ Restoring database..."
turso db restore autoforge-nexus-$ENVIRONMENT \
  --from-backup $BACKUP_DATE

# 4. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†ãƒ‡ãƒ—ãƒ­ã‚¤
echo "ğŸš€ Redeploying applications..."
wrangler deploy --env $ENVIRONMENT

# 5. æ¤œè¨¼
echo "ğŸ§ª Validating recovery..."
curl -f https://api-${ENVIRONMENT}.autoforgenexus.com/health
curl -f https://${ENVIRONMENT}.autoforgenexus.com

echo "âœ… Disaster recovery completed successfully!"
```

## ğŸ“Š ã‚³ã‚¹ãƒˆç®¡ç†

### ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç›£è¦–
```hcl
# modules/cost_monitoring/main.tf
resource "cloudflare_worker_script" "cost_monitor" {
  account_id = var.cloudflare_account_id
  name       = "cost-monitor"
  content    = file("${path.module}/cost-monitor.js")

  # æ¯æ—¥å®Ÿè¡Œã®cron trigger
  trigger {
    cron = "0 9 * * *"  # æ¯æœ9æ™‚
  }
}

# ã‚³ã‚¹ãƒˆé–¾å€¤ã‚¢ãƒ©ãƒ¼ãƒˆ
resource "aws_budgets_budget" "autoforge_budget" {
  name         = "AutoForgeNexus-Monthly"
  budget_type  = "COST"
  limit_amount = "50"
  limit_unit   = "USD"
  time_unit    = "MONTHLY"

  cost_filters = {
    Service = [
      "Amazon S3",
      "AWS Lambda"
    ]
  }

  notification {
    comparison_operator        = "GREATER_THAN"
    threshold                 = 80
    threshold_type            = "PERCENTAGE"
    notification_type         = "ACTUAL"
    subscriber_email_addresses = ["devops@autoforgenexus.com"]
  }
}
```

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–

### Secretç®¡ç†
```hcl
# modules/secrets/main.tf
resource "aws_secretsmanager_secret" "app_secrets" {
  name                    = "autoforge-nexus/${var.environment}"
  description             = "Application secrets for AutoForge Nexus"
  recovery_window_in_days = 7

  replica {
    region = "us-west-2"
  }
}

resource "aws_secretsmanager_secret_version" "app_secrets" {
  secret_id = aws_secretsmanager_secret.app_secrets.id
  secret_string = jsonencode({
    jwt_secret_key = random_password.jwt_secret.result
    openai_api_key = var.openai_api_key
    anthropic_api_key = var.anthropic_api_key
    clerk_secret_key = var.clerk_secret_key
  })
}

resource "random_password" "jwt_secret" {
  length  = 64
  special = true
}
```

## ğŸ“ˆ é‹ç”¨ç›£è¦–

### ã‚¤ãƒ³ãƒ•ãƒ©ãƒ‰ãƒªãƒ•ãƒˆæ¤œçŸ¥
```bash
#!/bin/bash
# scripts/drift_detection.sh

echo "ğŸ” Checking for infrastructure drift..."

for env in dev staging prod; do
  echo "Checking $env environment..."

  cd infrastructure/environments/$env

  # ãƒ‰ãƒªãƒ•ãƒˆæ¤œçŸ¥
  terraform plan -detailed-exitcode -out=drift-check.plan
  EXIT_CODE=$?

  if [ $EXIT_CODE -eq 2 ]; then
    echo "âš ï¸ Drift detected in $env environment!"
    terraform show drift-check.plan

    # Slacké€šçŸ¥
    curl -X POST $SLACK_WEBHOOK_URL \
      -H 'Content-type: application/json' \
      --data "{\"text\":\"ğŸš¨ Infrastructure drift detected in $env environment\"}"
  else
    echo "âœ… No drift in $env environment"
  fi

  cd ../../..
done
```

## ğŸ¯ å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

### Week 1: åŸºç›¤æ§‹ç¯‰
- [ ] Terraformç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- [ ] ãƒªãƒ¢ãƒ¼ãƒˆstateè¨­å®š
- [ ] åŸºæœ¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ

### Week 2: ä¸»è¦ãƒªã‚½ãƒ¼ã‚¹
- [ ] Cloudflare Workers/Pages
- [ ] Turso ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
- [ ] åŸºæœ¬ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š

### Week 3: ç›£è¦–ãƒ»è‡ªå‹•åŒ–
- [ ] ç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯
- [ ] CI/CDçµ±åˆ
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è‡ªå‹•åŒ–

### Week 4: é‹ç”¨æœ€é©åŒ–
- [ ] ãƒ‰ãƒªãƒ•ãƒˆæ¤œçŸ¥
- [ ] ã‚³ã‚¹ãƒˆç›£è¦–
- [ ] ç½å®³å¾©æ—§ãƒ†ã‚¹ãƒˆ