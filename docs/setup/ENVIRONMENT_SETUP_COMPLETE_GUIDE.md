# AutoForgeNexus ç’°å¢ƒæ§‹ç¯‰å®Œå…¨ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ **æ¦‚è¦**

AutoForgeNexus
AI ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ç’°å¢ƒæ§‹ç¯‰ã‚’æ®µéšçš„ã«å®Ÿè¡Œã™ã‚‹ãŸã‚ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚å„ã‚³ãƒãƒ³ãƒ‰ã®è©³ç´°ãªæŒ‡ç¤ºã€AI ã¸ã®å…·ä½“çš„ãªã‚³ãƒ¡ãƒ³ãƒˆã€è¨­å®šã€ä»•æ§˜ã‚’å«ã‚ã€ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã•ã›ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªæ‰‹é †æ›¸ã‚’æä¾›ã—ã¾ã™ã€‚

## ğŸ¯ **ç›®çš„**

- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆPython 3.13 + FastAPIï¼‰ç’°å¢ƒã®å®Œå…¨æ§‹ç¯‰
- ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆNext.js 15.5 + React 19ï¼‰ç’°å¢ƒã®å®Œå…¨æ§‹ç¯‰
- Gitãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ç’°å¢ƒã®æœ€é©åŒ–è¨­å®š
- ã‚¤ãƒ³ãƒ•ãƒ©ï¼ˆCloudflare + Dockerï¼‰ç’°å¢ƒã®æ§‹ç¯‰
- å“è³ªä¿è¨¼ãƒ»ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰

## ğŸ“š **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ§‹æˆ**

### **ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥è©³ç´°ã‚¬ã‚¤ãƒ‰**

- [Phase 1: Gitãƒ»åŸºç›¤ç’°å¢ƒæ§‹ç¯‰](#phase-1-gitåŸºç›¤ç’°å¢ƒæ§‹ç¯‰)
- [Phase 2: ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»DevOpsç’°å¢ƒæ§‹ç¯‰](#phase-2-ã‚¤ãƒ³ãƒ•ãƒ©devopsç’°å¢ƒæ§‹ç¯‰)
- [Phase 3: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ§‹ç¯‰](#phase-3-ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ§‹ç¯‰)
- [Phase 4: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ™ã‚¯ãƒˆãƒ«ç’°å¢ƒæ§‹ç¯‰](#phase-4-ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ™ã‚¯ãƒˆãƒ«ç’°å¢ƒæ§‹ç¯‰)
- [Phase 5: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ§‹ç¯‰](#phase-5-ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ§‹ç¯‰)
- [Phase 6: çµ±åˆãƒ»å“è³ªä¿è¨¼](#phase-6-çµ±åˆå“è³ªä¿è¨¼)

### **è£œåŠ©è³‡æ–™**

- [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
- [FAQ](#faq)
- [å‚è€ƒè³‡æ–™](#å‚è€ƒè³‡æ–™)

---

# Phase 1: Gitãƒ»åŸºç›¤ç’°å¢ƒæ§‹ç¯‰

## ğŸš€ **ç›®æ¨™**

Gitç’°å¢ƒã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºç›¤ã®ç¢ºç«‹ã«ã‚ˆã‚Šã€å…¨ã¦ã®é–‹ç™ºä½œæ¥­ã®åŸºç›¤ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

## ğŸ“‹ **å‰ææ¡ä»¶**

### **å¿…é ˆãƒ„ãƒ¼ãƒ«ç¢ºèª**

```bash
# Git ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ2.40+å¿…é ˆï¼‰
git --version
# Node.js ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ20+å¿…é ˆï¼‰
node --version
# Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ3.13å¿…é ˆï¼‰
python3.13 --version
# pnpm ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ8+å¿…é ˆï¼‰
pnpm --version
# Docker ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ24+å¿…é ˆï¼‰
docker --version
```

## ğŸ”§ **Step 1.1: Gitç’°å¢ƒã¨ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ã®ç¢ºç«‹**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:development:git init --strategy gitflow --hooks --semantic-version
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

```markdown
# Git ç’°å¢ƒæ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

1. GitFlow ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ã®å®Œå…¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
2. pre-commitã€commit-msgã€pre-push ãƒ•ãƒƒã‚¯ã®è¨­å®š
3. semantic versioning å¯¾å¿œã®è¨­å®š
4. ãƒ–ãƒ©ãƒ³ãƒä¿è­·ãƒ«ãƒ¼ãƒ«ã®è¨­å®š

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### GitFlow ãƒ–ãƒ©ãƒ³ãƒè¨­å®š

- main: æœ¬ç•ªãƒªãƒªãƒ¼ã‚¹ç”¨
- develop: é–‹ç™ºçµ±åˆç”¨
- feature/\*: æ©Ÿèƒ½é–‹ç™ºç”¨
- release/\*: ãƒªãƒªãƒ¼ã‚¹æº–å‚™ç”¨
- hotfix/\*: ç·Šæ€¥ä¿®æ­£ç”¨

### Git ãƒ•ãƒƒã‚¯è¨­å®š

- pre-commit: ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆruff, mypy, prettierï¼‰
- commit-msg: Conventional Commits å¼·åˆ¶
- pre-push: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã¨ãƒ“ãƒ«ãƒ‰ç¢ºèª

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

- .gitignore: Python, Node.js, Dockerå¯¾å¿œ
- .gitmessage: ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
- CODEOWNERS: ã‚³ãƒ¼ãƒ‰ã‚ªãƒ¼ãƒŠãƒ¼è¨­å®š

### ãƒ–ãƒ©ãƒ³ãƒä¿è­·è¨­å®š

- main, develop ãƒ–ãƒ©ãƒ³ãƒã® direct push ç¦æ­¢
- PR ãƒãƒ¼ã‚¸å‰ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…é ˆ
- status check å¿…é ˆï¼ˆCI/CD ãƒ‘ã‚¹ï¼‰

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- å®Œå…¨ã«è¨­å®šã•ã‚ŒãŸ Git ãƒªãƒã‚¸ãƒˆãƒª
- ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ã®æ–‡æ›¸åŒ–
- é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¬ã‚¤ãƒ‰
```

### **æ¤œè¨¼æ–¹æ³•**

```bash
# ãƒ–ãƒ©ãƒ³ãƒç¢ºèª
git branch -a
git flow version

# ãƒ•ãƒƒã‚¯ç¢ºèª
ls -la .git/hooks/

# è¨­å®šç¢ºèª
cat .gitignore
cat .gitmessage
cat CODEOWNERS
```

---

## ğŸ”§ **Step 1.2: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºç›¤åˆæœŸåŒ–**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:core:init AutoForgeNexus --phase 1 --agents core --env dev --ddd
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

```markdown
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºç›¤åˆæœŸåŒ–æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

DDD åŸå‰‡ã«åŸºã¥ããƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®æ§‹ç¯‰ã¨ Phase 1 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ã®èµ·å‹•

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆ
```

/backend/ # Python/FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ /src/
/domain/ # ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ /entities/ # ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ /value_objects/ # å€¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ /repositories/ # ãƒªãƒã‚¸ãƒˆãƒªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ /services/ # ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚µãƒ¼ãƒ“ã‚¹ /application/ # ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã¨ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒ“ã‚¹ /use_cases/ # ãƒ“ã‚¸ãƒã‚¹ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ /services/ # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒ“ã‚¹ /dtos/ # ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ /infrastructure/ # å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£… /repositories/ # ãƒªãƒã‚¸ãƒˆãƒªå®Ÿè£… /external/ # å¤–éƒ¨APIçµ±åˆ /database/ # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š /presentation/ #
APIã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã¨ã‚¹ã‚­ãƒ¼ãƒ /api/ # FastAPI ãƒ«ãƒ¼ã‚¿ãƒ¼ /schemas/ #
Pydantic ã‚¹ã‚­ãƒ¼ãƒ /middleware/ # ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ /tests/ # ãƒ†ã‚¹ãƒˆ /unit/ # ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ /integration/ # çµ±åˆãƒ†ã‚¹ãƒˆ /e2e/ #
E2Eãƒ†ã‚¹ãƒˆ /migrations/ # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ /scripts/ # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

/frontend/ # Next.js/React ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ /src/ /app/ # Next.js 15 App Router
/components/ # å†åˆ©ç”¨å¯èƒ½UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ /ui/ # åŸºæœ¬UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ /features/ # æ©Ÿèƒ½å›ºæœ‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ /layout/ # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ /hooks/ # ã‚«ã‚¹ã‚¿ãƒ Reactãƒ•ãƒƒã‚¯ /stores/ #
ZustandçŠ¶æ…‹ç®¡ç† /lib/ # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ /types/ #
TypeScriptå‹å®šç¾© /public/ # é™çš„ãƒ•ã‚¡ã‚¤ãƒ« /tests/ # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ /**tests**/ #
Jest ãƒ†ã‚¹ãƒˆ /e2e/ # Playwright E2Eãƒ†ã‚¹ãƒˆ

/docs/ # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ /architecture/ # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ /api/ #
API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ /development/ # é–‹ç™ºã‚¬ã‚¤ãƒ‰ /deployment/ # ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¬ã‚¤ãƒ‰

/infrastructure/ # ã‚¤ãƒ³ãƒ•ãƒ©è¨­å®š /docker/ # Dockerè¨­å®š /terraform/ #
Terraformè¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰/kubernetes/ # K8sè¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰

````

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

#### backend/pyproject.toml
```toml
[project]
name = "autoforge-nexus-backend"
version = "0.1.0"
description = "AutoForgeNexus Backend API"
requires-python = ">=3.13"
dependencies = [
    "fastapi==0.116.1",
    "sqlalchemy==2.0.32",
    "pydantic==2.9.2",
    "uvicorn==0.32.0",
    "python-dotenv==1.0.1",
    "redis==5.2.0",
    "langchain==0.3.27",
    "langgraph==0.6.7",
    "litellm==1.76.1",
    "langfuse==2.56.2"
]

[project.optional-dependencies]
dev = [
    "pytest==8.3.3",
    "pytest-asyncio==0.24.0",
    "ruff==0.7.4",
    "mypy==1.13.0",
    "black==24.10.0"
]

[tool.ruff]
line-length = 88
target-version = "py313"

[tool.mypy]
python_version = "3.13"
strict = true
````

#### frontend/package.json

```json
{
  "name": "autoforge-nexus-frontend",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "type-check": "tsc --noEmit",
    "test": "jest",
    "test:e2e": "playwright test"
  },
  "dependencies": {
    "next": "15.5.0",
    "react": "19.0.0",
    "react-dom": "19.0.0",
    "typescript": "5.6.3",
    "tailwindcss": "4.0.0"
  },
  "devDependencies": {
    "@types/react": "19.0.0",
    "@types/react-dom": "19.0.0",
    "eslint": "9.15.0",
    "eslint-config-next": "15.5.0",
    "prettier": "3.3.3",
    "jest": "29.7.0",
    "@playwright/test": "1.48.0"
  }
}
```

#### docker-compose.dev.yml

```yaml
version: '3.8'

services:
  backend:
    build: ./backend
    ports:
      - '8000:8000'
    environment:
      - DATABASE_URL=sqlite:///./autoforge.db
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./backend:/app
    depends_on:
      - redis

  frontend:
    build: ./frontend
    ports:
      - '3000:3000'
    volumes:
      - ./frontend:/app
    depends_on:
      - backend

  redis:
    image: redis:7-alpine
    ports:
      - '6379:6379'

  langfuse:
    image: langfuse/langfuse:latest
    ports:
      - '3001:3000'
    environment:
      - DATABASE_URL=postgresql://langfuse:password@langfuse-db:5432/langfuse
    depends_on:
      - langfuse-db

  langfuse-db:
    image: postgres:16
    environment:
      - POSTGRES_USER=langfuse
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=langfuse
    volumes:
      - langfuse_data:/var/lib/postgresql/data

volumes:
  langfuse_data:
```

### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèµ·å‹•ç¢ºèª

Phase 1 ã§èµ·å‹•ã•ã‚Œã‚‹ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆ7ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰:

- system-architect (ãƒªãƒ¼ãƒ€ãƒ¼)
- domain-modeller
- backend-developer
- database-administrator
- devops-coordinator
- security-architect
- version-control-specialist

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- DDDæº–æ‹ ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 
- å¿…è¦ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸€å¼
- Dockeré–‹ç™ºç’°å¢ƒ
- Phase 1 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ èµ·å‹•

````

### **æ¤œè¨¼æ–¹æ³•**
```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ç¢ºèª
tree -L 3

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
cat backend/pyproject.toml
cat frontend/package.json
cat docker-compose.dev.yml

# Dockerç’°å¢ƒèµ·å‹•ãƒ†ã‚¹ãƒˆ
docker-compose -f docker-compose.dev.yml up --build -d
docker-compose -f docker-compose.dev.yml ps
````

---

# Phase 2: ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»DevOpsç’°å¢ƒæ§‹ç¯‰

## ğŸš€ **ç›®æ¨™**

Cloudflareã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’æ´»ç”¨ã—ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤ã¨ã€è¦³æ¸¬å¯èƒ½æ€§ã‚’æŒã¤ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã€‚

## ğŸ”§ **Step 2.1: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥ã¨ã‚¤ãƒ³ãƒ•ãƒ©æº–å‚™**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:operations:deploy dev --strategy rolling --edge
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

````markdown
# ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

Cloudflare ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’æ´»ç”¨ã—ãŸé–‹ç™ºç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåŸºç›¤ã®æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### Cloudflare è¨­å®š

1. **Cloudflare Workers è¨­å®š**

   - backend API ç”¨ Worker è¨­å®š
   - ã‚¨ãƒƒã‚¸ã§ã® API å‡¦ç†è¨­å®š
   - KV ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¨­å®š

2. **Cloudflare Pages è¨­å®š**

   - frontend é™çš„ã‚µã‚¤ãƒˆé…ä¿¡
   - ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ—ãƒ­ã‚¤è¨­å®š
   - ã‚«ã‚¹ã‚¿ãƒ ãƒ‰ãƒ¡ã‚¤ãƒ³è¨­å®š

3. **Cloudflare R2 è¨­å®š**
   - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¨­å®š
   - CDN é…ä¿¡è¨­å®š

### Docker è¨­å®šæœ€é©åŒ–

#### backend/Dockerfile

```dockerfile
FROM python:3.13-slim

WORKDIR /app

# Install dependencies
COPY pyproject.toml .
RUN pip install -e .

# Copy source code
COPY src/ ./src/
COPY migrations/ ./migrations/

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "src.presentation.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```
````

#### frontend/Dockerfile

```dockerfile
FROM node:20-alpine AS base

# Install pnpm
RUN corepack enable

FROM base AS deps
WORKDIR /app
COPY package.json pnpm-lock.yaml ./
RUN pnpm install --frozen-lockfile

FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .
RUN pnpm build

FROM base AS runner
WORKDIR /app
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

COPY --from=builder /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs
EXPOSE 3000
ENV PORT 3000
ENV HOSTNAME "0.0.0.0"

CMD ["node", "server.js"]
```

### CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š

#### .github/workflows/deploy-dev.yml

```yaml
name: Deploy Development

on:
  push:
    branches: [develop]
  pull_request:
    branches: [develop]

jobs:
  test-backend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: '3.13'
      - name: Install dependencies
        run: |
          cd backend
          pip install -e .[dev]
      - name: Run tests
        run: |
          cd backend
          pytest
      - name: Run linting
        run: |
          cd backend
          ruff check
          mypy src/

  test-frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v2
        with:
          version: 8
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
      - name: Install dependencies
        run: |
          cd frontend
          pnpm install
      - name: Run tests
        run: |
          cd frontend
          pnpm test
      - name: Type check
        run: |
          cd frontend
          pnpm type-check
      - name: Lint
        run: |
          cd frontend
          pnpm lint

  deploy-backend:
    needs: [test-backend, test-frontend]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    steps:
      - uses: actions/checkout@v4
      - name: Deploy to Cloudflare Workers
        run: |
          cd backend
          wrangler deploy

  deploy-frontend:
    needs: [test-backend, test-frontend]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    steps:
      - uses: actions/checkout@v4
      - name: Deploy to Cloudflare Pages
        run: |
          cd frontend
          pnpm build
          wrangler pages deploy dist
```

### Rolling Deployment æˆ¦ç•¥

1. **æ®µéšçš„ãƒ‡ãƒ—ãƒ­ã‚¤**

   - 20% â†’ 50% â†’ 100% ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ç§»è¡Œ
   - å„æ®µéšã§ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
   - ç•°å¸¸æ¤œçŸ¥æ™‚ã®è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

2. **ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯è¨­å®š**
   - API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å¿œç­”ç¢ºèª
   - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
   - å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹é€£æºç¢ºèª

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- Cloudflare ç’°å¢ƒã®å®Œå…¨è¨­å®š
- Docker ã‚³ãƒ³ãƒ†ãƒŠã®æœ€é©åŒ–
- CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- Rolling Deployment è¨­å®š

````

### **æ¤œè¨¼æ–¹æ³•**
```bash
# Docker ãƒ“ãƒ«ãƒ‰ãƒ†ã‚¹ãƒˆ
docker build -t autoforge-backend ./backend
docker build -t autoforge-frontend ./frontend

# Cloudflare è¨­å®šç¢ºèª
wrangler whoami
wrangler pages project list

# CI/CD å‹•ä½œç¢ºèª
git push origin develop
````

---

## ğŸ”§ **Step 2.2: ç›£è¦–ãƒ»è¦³æ¸¬å¯èƒ½æ€§ã®è¨­å®š**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:operations:monitor system --metrics --traces --logs --alerts
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

````markdown
# ç›£è¦–ãƒ»è¦³æ¸¬å¯èƒ½æ€§æ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

3 ã¤ã®æŸ±ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã€ãƒ­ã‚°ï¼‰ã‚’çµ±åˆã—ãŸåŒ…æ‹¬çš„ç›£è¦–ä½“åˆ¶ã®æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### 1. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†è¨­å®š

#### backend/src/presentation/middleware/metrics.py

```python
from prometheus_client import Counter, Histogram, generate_latest
import time
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

class MetricsMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()

        response = await call_next(request)

        duration = time.time() - start_time
        REQUEST_DURATION.labels(
            method=request.method,
            endpoint=request.url.path
        ).observe(duration)

        REQUEST_COUNT.labels(
            method=request.method,
            endpoint=request.url.path,
            status=response.status_code
        ).inc()

        return response
```
````

#### frontend/src/lib/monitoring.ts

```typescript
// Web Vitals åé›†
import { getCLS, getFID, getFCP, getLCP, getTTFB } from 'web-vitals';

export function initWebVitals() {
  getCLS(sendToAnalytics);
  getFID(sendToAnalytics);
  getFCP(sendToAnalytics);
  getLCP(sendToAnalytics);
  getTTFB(sendToAnalytics);
}

function sendToAnalytics(metric: any) {
  // Cloudflare Analytics ã«é€ä¿¡
  fetch('/api/analytics', {
    method: 'POST',
    body: JSON.stringify(metric),
  });
}

// ã‚¨ãƒ©ãƒ¼ç›£è¦–
export function initErrorMonitoring() {
  window.addEventListener('error', (event) => {
    console.error('JavaScript Error:', event.error);
    // ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®é€ä¿¡
    fetch('/api/errors', {
      method: 'POST',
      body: JSON.stringify({
        message: event.error?.message,
        stack: event.error?.stack,
        url: window.location.href,
        timestamp: new Date().toISOString(),
      }),
    });
  });
}
```

### 2. åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°è¨­å®š

#### backend/src/infrastructure/tracing.py

```python
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor

def init_tracing(app):
    # Tracer Provider è¨­å®š
    trace.set_tracer_provider(TracerProvider())
    tracer = trace.get_tracer(__name__)

    # Jaeger Exporter è¨­å®š
    jaeger_exporter = JaegerExporter(
        agent_host_name="localhost",
        agent_port=14268,
    )

    # Span Processor è¨­å®š
    span_processor = BatchSpanProcessor(jaeger_exporter)
    trace.get_tracer_provider().add_span_processor(span_processor)

    # FastAPI è‡ªå‹•è¨ˆè£…
    FastAPIInstrumentor.instrument_app(app)

    # SQLAlchemy è‡ªå‹•è¨ˆè£…
    SQLAlchemyInstrumentor().instrument()

    return tracer
```

### 3. æ§‹é€ åŒ–ãƒ­ã‚°è¨­å®š

#### backend/src/infrastructure/logging.py

```python
import structlog
import logging
from typing import Any, Dict

def configure_logging():
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,
            structlog.processors.add_log_level,
            structlog.processors.StackInfoRenderer(),
            structlog.dev.set_exc_info,
            structlog.processors.JSONRenderer()
        ],
        wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
        logger_factory=structlog.WriteLoggerFactory(),
        cache_logger_on_first_use=False,
    )

logger = structlog.get_logger()

# ãƒ­ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
def log_context(**kwargs: Any) -> Dict[str, Any]:
    return {
        "service": "autoforge-nexus",
        "version": "0.1.0",
        **kwargs
    }
```

### 4. ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

#### monitoring/alerts.yml

```yaml
groups:
  - name: autoforge_alerts
    rules:
      - alert: HighErrorRate
        expr:
          (rate(http_requests_total{status=~"5.."}[5m]) /
          rate(http_requests_total[5m])) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: 'High error rate detected'
          description: 'Error rate is {{ $value }} for the last 5 minutes'

      - alert: HighResponseTime
        expr:
          histogram_quantile(0.95,
          rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'High response time detected'
          description: '95th percentile response time is {{ $value }}s'

      - alert: DatabaseConnectionFailure
        expr: up{job="database"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: 'Database connection failure'
          description: 'Database is not responding'
```

### 5. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š

#### monitoring/grafana-dashboard.json

```json
{
  "dashboard": {
    "title": "AutoForgeNexus Monitoring",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "Errors/sec"
          }
        ]
      }
    ]
  }
}
```

### 6. ç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯èµ·å‹•

#### docker-compose.monitoring.yml

```yaml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus
    ports:
      - '9090:9090'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/alerts.yml:/etc/prometheus/alerts.yml

  grafana:
    image: grafana/grafana
    ports:
      - '3001:3000'
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./monitoring/grafana-dashboard.json:/var/lib/grafana/dashboards/dashboard.json

  jaeger:
    image: jaegertracing/all-in-one
    ports:
      - '16686:16686'
      - '14268:14268'
    environment:
      - COLLECTOR_OTLP_ENABLED=true

  alertmanager:
    image: prom/alertmanager
    ports:
      - '9093:9093'
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml
```

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- å®Œå…¨ãªç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã€ãƒ­ã‚°ã®çµ±åˆ
- ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- è‡ªå‹•ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 

````

### **æ¤œè¨¼æ–¹æ³•**
```bash
# ç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯èµ·å‹•
docker-compose -f docker-compose.monitoring.yml up -d

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¢ºèª
curl http://localhost:9090  # Prometheus
curl http://localhost:3001  # Grafana
curl http://localhost:16686 # Jaeger

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèª
curl http://localhost:8000/metrics
````

---

# Phase 3: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ§‹ç¯‰

## ğŸš€ **ç›®æ¨™**

DDDåŸå‰‡ã¨ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ãå …ç‰¢ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã€‚

## ğŸ”§ **Step 3.1: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:architecture:design microservices --ddd --event-driven --scale horizontal
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

```markdown
# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆæŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

DDD + ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹• + æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œã®ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹è¨­è¨ˆ

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### 1. ãƒ‰ãƒ¡ã‚¤ãƒ³å¢ƒç•Œã®å®šç¾©
```

Bounded Contexts:

1. Prompt Context (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†)

   - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: Prompt, Template, Version
   - å€¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: PromptContent, Quality, Style

2. Evaluation Context (è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ )

   - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: Evaluation, Metric, Benchmark
   - å€¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: Score, Feedback, Criteria

3. User Context (ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†)

   - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: User, Organization, Subscription
   - å€¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: UserProfile, Preferences

4. LLM Context (LLMçµ±åˆ)

   - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: Provider, Model, APIKey
   - å€¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: Usage, Cost, Limits

5. Workflow Context (ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼)
   - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: Workflow, Step, Execution
   - å€¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: Configuration, Status

````

### 2. ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹æ§‹æˆ
```python
# backend/src/domain/prompt/entities/prompt.py
from dataclasses import dataclass
from typing import Optional, List
from uuid import UUID, uuid4
from datetime import datetime

from ..value_objects import PromptContent, Quality, Style
from ...shared.entity import Entity
from ...shared.domain_events import DomainEvent

@dataclass
class PromptCreated(DomainEvent):
    prompt_id: UUID
    user_id: UUID
    content: str
    created_at: datetime

@dataclass
class PromptUpdated(DomainEvent):
    prompt_id: UUID
    user_id: UUID
    old_content: str
    new_content: str
    updated_at: datetime

class Prompt(Entity):
    def __init__(
        self,
        user_id: UUID,
        content: PromptContent,
        title: str,
        description: Optional[str] = None,
        style: Optional[Style] = None,
        quality: Optional[Quality] = None
    ):
        super().__init__()
        self._user_id = user_id
        self._content = content
        self._title = title
        self._description = description
        self._style = style
        self._quality = quality
        self._created_at = datetime.utcnow()
        self._updated_at = datetime.utcnow()

        # ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆè¿½åŠ 
        self.add_domain_event(PromptCreated(
            prompt_id=self.id,
            user_id=user_id,
            content=content.value,
            created_at=self._created_at
        ))

    def update_content(self, new_content: PromptContent) -> None:
        old_content = self._content.value
        self._content = new_content
        self._updated_at = datetime.utcnow()

        self.add_domain_event(PromptUpdated(
            prompt_id=self.id,
            user_id=self._user_id,
            old_content=old_content,
            new_content=new_content.value,
            updated_at=self._updated_at
        ))

    @property
    def content(self) -> PromptContent:
        return self._content

    @property
    def user_id(self) -> UUID:
        return self._user_id
````

### 3. ãƒªãƒã‚¸ãƒˆãƒªãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè£…

```python
# backend/src/domain/prompt/repositories/prompt_repository.py
from abc import ABC, abstractmethod
from typing import List, Optional
from uuid import UUID

from ..entities import Prompt

class PromptRepository(ABC):
    @abstractmethod
    async def save(self, prompt: Prompt) -> None:
        pass

    @abstractmethod
    async def get_by_id(self, prompt_id: UUID) -> Optional[Prompt]:
        pass

    @abstractmethod
    async def get_by_user_id(self, user_id: UUID) -> List[Prompt]:
        pass

    @abstractmethod
    async def delete(self, prompt_id: UUID) -> None:
        pass

# backend/src/infrastructure/repositories/sqlalchemy_prompt_repository.py
from typing import List, Optional
from uuid import UUID
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete

from ...domain.prompt.repositories import PromptRepository
from ...domain.prompt.entities import Prompt
from ..models import PromptModel

class SQLAlchemyPromptRepository(PromptRepository):
    def __init__(self, session: AsyncSession):
        self._session = session

    async def save(self, prompt: Prompt) -> None:
        model = PromptModel.from_entity(prompt)
        self._session.add(model)
        await self._session.commit()

    async def get_by_id(self, prompt_id: UUID) -> Optional[Prompt]:
        result = await self._session.execute(
            select(PromptModel).where(PromptModel.id == prompt_id)
        )
        model = result.scalar_one_or_none()
        return model.to_entity() if model else None
```

### 4. ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹å®Ÿè£…

```python
# backend/src/application/use_cases/create_prompt.py
from dataclasses import dataclass
from uuid import UUID
from typing import Optional

from ...domain.prompt.entities import Prompt
from ...domain.prompt.repositories import PromptRepository
from ...domain.prompt.value_objects import PromptContent
from ..services import EventPublisher

@dataclass
class CreatePromptCommand:
    user_id: UUID
    content: str
    title: str
    description: Optional[str] = None

class CreatePromptUseCase:
    def __init__(
        self,
        prompt_repository: PromptRepository,
        event_publisher: EventPublisher
    ):
        self._prompt_repository = prompt_repository
        self._event_publisher = event_publisher

    async def execute(self, command: CreatePromptCommand) -> UUID:
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
        prompt_content = PromptContent(command.content)
        prompt = Prompt(
            user_id=command.user_id,
            content=prompt_content,
            title=command.title,
            description=command.description
        )

        # æ°¸ç¶šåŒ–
        await self._prompt_repository.save(prompt)

        # ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆç™ºè¡Œ
        for event in prompt.domain_events:
            await self._event_publisher.publish(event)

        return prompt.id
```

### 5. FastAPI ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼

```python
# backend/src/presentation/api/prompt_controller.py
from fastapi import APIRouter, Depends, HTTPException, status
from uuid import UUID
from typing import List

from ...application.use_cases import CreatePromptUseCase
from ...application.dtos import CreatePromptRequest, PromptResponse
from ..dependencies import get_create_prompt_use_case

router = APIRouter(prefix="/api/v1/prompts", tags=["prompts"])

@router.post("/", response_model=PromptResponse, status_code=status.HTTP_201_CREATED)
async def create_prompt(
    request: CreatePromptRequest,
    use_case: CreatePromptUseCase = Depends(get_create_prompt_use_case)
):
    try:
        command = CreatePromptCommand(
            user_id=request.user_id,
            content=request.content,
            title=request.title,
            description=request.description
        )
        prompt_id = await use_case.execute(command)
        return PromptResponse(id=prompt_id, message="Prompt created successfully")
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
```

### 6. ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•çµ±åˆ

```python
# backend/src/infrastructure/events/event_bus.py
from typing import Dict, List, Callable
from dataclasses import asdict
import json
import asyncio
import redis.asyncio as redis

from ...domain.shared.domain_events import DomainEvent

class EventBus:
    def __init__(self, redis_client: redis.Redis):
        self._redis = redis_client
        self._handlers: Dict[str, List[Callable]] = {}

    def subscribe(self, event_type: str, handler: Callable):
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

    async def publish(self, event: DomainEvent):
        event_data = {
            "event_type": event.__class__.__name__,
            "data": asdict(event),
            "timestamp": event.occurred_at.isoformat()
        }

        # Redis Streams ã«ç™ºè¡Œ
        await self._redis.xadd(
            f"events:{event.__class__.__name__}",
            event_data
        )

        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼å®Ÿè¡Œ
        handlers = self._handlers.get(event.__class__.__name__, [])
        for handler in handlers:
            asyncio.create_task(handler(event))
```

### 7. æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œ

```python
# backend/src/infrastructure/scaling/load_balancer.py
from typing import List
import random
import httpx
from dataclasses import dataclass

@dataclass
class ServiceInstance:
    host: str
    port: int
    health: bool = True
    load: int = 0

class LoadBalancer:
    def __init__(self):
        self._instances: List[ServiceInstance] = []

    def add_instance(self, host: str, port: int):
        self._instances.append(ServiceInstance(host, port))

    def get_instance(self) -> ServiceInstance:
        # ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ + è² è·è€ƒæ…®
        healthy_instances = [i for i in self._instances if i.health]
        if not healthy_instances:
            raise Exception("No healthy instances available")

        # è² è·ãŒæœ€ã‚‚ä½ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’é¸æŠ
        return min(healthy_instances, key=lambda x: x.load)

    async def health_check(self):
        for instance in self._instances:
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get(
                        f"http://{instance.host}:{instance.port}/health",
                        timeout=5.0
                    )
                    instance.health = response.status_code == 200
            except:
                instance.health = False
```

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- DDDæº–æ‹ ã®ãƒ‰ãƒ¡ã‚¤ãƒ³è¨­è¨ˆ
- ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œã®è¨­è¨ˆ
- ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å¢ƒç•Œã®æ˜ç¢ºåŒ–
- å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ä¾‹ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

````

### **æ¤œè¨¼æ–¹æ³•**
```bash
# ãƒ‰ãƒ¡ã‚¤ãƒ³æ§‹é€ ç¢ºèª
tree backend/src/domain/

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
cd backend
pytest src/tests/unit/domain/
pytest src/tests/integration/

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¤œè¨¼
python -m pytest src/tests/architecture/
````

---

## ğŸ”§ **Step 3.2: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒªãƒ³ã‚°**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:requirements:domain prompt-context --aggregate root --event-sourcing --cqrs
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

````markdown
# ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒªãƒ³ã‚°è©³ç´°æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å®Œå…¨ãªãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã¨ã‚¤ãƒ™ãƒ³ãƒˆã‚½ãƒ¼ã‚·ãƒ³ã‚°å®Ÿè£…

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### 1. é›†ç´„ãƒ«ãƒ¼ãƒˆè¨­è¨ˆ

```python
# backend/src/domain/prompt/aggregates/prompt_aggregate.py
from typing import List, Optional
from uuid import UUID
from datetime import datetime

from ..entities import Prompt, PromptVersion, PromptTemplate
from ..value_objects import PromptContent, Quality, Style
from ..events import (
    PromptCreated, PromptUpdated, PromptOptimized,
    PromptPublished, PromptArchived
)
from ...shared.aggregate_root import AggregateRoot

class PromptAggregate(AggregateRoot):
    def __init__(self, prompt_id: UUID):
        super().__init__(prompt_id)
        self._prompt: Optional[Prompt] = None
        self._versions: List[PromptVersion] = []
        self._templates: List[PromptTemplate] = []
        self._published = False
        self._archived = False

    def create_prompt(
        self,
        user_id: UUID,
        content: PromptContent,
        title: str,
        description: Optional[str] = None
    ) -> None:
        if self._prompt is not None:
            raise ValueError("Prompt already exists")

        self._prompt = Prompt(
            id=self.id,
            user_id=user_id,
            content=content,
            title=title,
            description=description
        )

        self.add_event(PromptCreated(
            aggregate_id=self.id,
            user_id=user_id,
            content=content.value,
            title=title,
            description=description,
            occurred_at=datetime.utcnow()
        ))
```
````

### 2. ã‚¤ãƒ™ãƒ³ãƒˆã‚½ãƒ¼ã‚·ãƒ³ã‚°å®Ÿè£…

```python
# backend/src/infrastructure/event_store/event_store.py
import json
from typing import List, Optional, Type
from uuid import UUID
from dataclasses import asdict
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_

from ...domain.shared.domain_events import DomainEvent
from ..models.event_model import EventModel

class EventStore:
    def __init__(self, session: AsyncSession):
        self._session = session

    async def save_events(
        self,
        aggregate_id: UUID,
        events: List[DomainEvent],
        expected_version: int
    ) -> None:
        # æ¥½è¦³çš„ãƒ­ãƒƒã‚¯ç¢ºèª
        current_version = await self.get_version(aggregate_id)
        if current_version != expected_version:
            raise ConcurrencyError(
                f"Expected version {expected_version}, got {current_version}"
            )

        # ã‚¤ãƒ™ãƒ³ãƒˆä¿å­˜
        for i, event in enumerate(events):
            event_model = EventModel(
                aggregate_id=aggregate_id,
                event_type=event.__class__.__name__,
                event_data=json.dumps(asdict(event)),
                version=expected_version + i + 1,
                occurred_at=event.occurred_at
            )
            self._session.add(event_model)

        await self._session.commit()
```

### 3. CQRSå®Ÿè£…

```python
# backend/src/application/queries/prompt_queries.py
from typing import List, Optional
from uuid import UUID
from dataclasses import dataclass
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_

from ...infrastructure.read_models import PromptReadModel

@dataclass
class PromptSummary:
    id: UUID
    title: str
    description: Optional[str]
    user_id: UUID
    created_at: datetime
    updated_at: datetime
    quality_score: Optional[float]
    published: bool

class PromptQueryService:
    def __init__(self, session: AsyncSession):
        self._session = session

    async def get_prompt_by_id(self, prompt_id: UUID) -> Optional[PromptSummary]:
        result = await self._session.execute(
            select(PromptReadModel)
            .where(PromptReadModel.id == prompt_id)
        )
        model = result.scalar_one_or_none()

        if not model:
            return None

        return PromptSummary(
            id=model.id,
            title=model.title,
            description=model.description,
            user_id=model.user_id,
            created_at=model.created_at,
            updated_at=model.updated_at,
            quality_score=model.quality_score,
            published=model.published
        )
```

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- å®Œå…¨ãªé›†ç´„ãƒ«ãƒ¼ãƒˆå®Ÿè£…
- ã‚¤ãƒ™ãƒ³ãƒˆã‚½ãƒ¼ã‚·ãƒ³ã‚°åŸºç›¤
- CQRSèª­ã¿æ›¸ãåˆ†é›¢
- ã‚¤ãƒ™ãƒ³ãƒˆæŠ•å½±æ©Ÿèƒ½
- æ¥½è¦³çš„ãƒ­ãƒƒã‚¯æ©Ÿèƒ½

````

### **æ¤œè¨¼æ–¹æ³•**
```bash
# ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ
pytest src/tests/unit/domain/prompt/

# ã‚¤ãƒ™ãƒ³ãƒˆã‚½ãƒ¼ã‚·ãƒ³ã‚°ç¢ºèª
python -c "
from src.domain.prompt.aggregates import PromptAggregate
from src.domain.prompt.value_objects import PromptContent
from uuid import uuid4

aggregate = PromptAggregate(uuid4())
aggregate.create_prompt(uuid4(), PromptContent('test'), 'Test Prompt')
print(f'Events: {len(aggregate.uncommitted_events)}')
"
````

---

## ğŸ”§ **Step 3.3: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å®Ÿè£…åŸºç›¤**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:development:implement backend-core --tdd --coverage 80 --parallel
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

````markdown
# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å®Ÿè£…åŸºç›¤æ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

TDDæ‰‹æ³•ã«ã‚ˆã‚Š80%ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’é”æˆã™ã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚³ã‚¢æ©Ÿèƒ½ã®å®Ÿè£…

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### 1. TDDã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ

#### Red Phase (å¤±æ•—ãƒ†ã‚¹ãƒˆä½œæˆ)

```python
# backend/src/tests/unit/domain/test_prompt_aggregate.py
import pytest
from uuid import uuid4
from datetime import datetime

from src.domain.prompt.aggregates import PromptAggregate
from src.domain.prompt.value_objects import PromptContent
from src.domain.prompt.events import PromptCreated

class TestPromptAggregate:
    def test_create_prompt_success(self):
        # Given
        aggregate_id = uuid4()
        user_id = uuid4()
        content = PromptContent("Test prompt content")
        title = "Test Prompt"

        # When
        aggregate = PromptAggregate(aggregate_id)
        aggregate.create_prompt(user_id, content, title)

        # Then
        assert aggregate.id == aggregate_id
        assert len(aggregate.uncommitted_events) == 1
        event = aggregate.uncommitted_events[0]
        assert isinstance(event, PromptCreated)
        assert event.user_id == user_id
        assert event.content == content.value
        assert event.title == title
```
````

### 2. ä¸¦åˆ—å®Ÿè£…æˆ¦ç•¥

```python
# backend/src/application/services/parallel_processor.py
import asyncio
from typing import List, Callable, Any
from concurrent.futures import ThreadPoolExecutor
import logging

logger = logging.getLogger(__name__)

class ParallelProcessor:
    def __init__(self, max_workers: int = 4):
        self._executor = ThreadPoolExecutor(max_workers=max_workers)

    async def process_batch(
        self,
        items: List[Any],
        processor: Callable,
        batch_size: int = 10
    ) -> List[Any]:
        """ãƒãƒƒãƒå‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œ"""
        results = []

        # ãƒãƒƒãƒã«åˆ†å‰²
        batches = [
            items[i:i + batch_size]
            for i in range(0, len(items), batch_size)
        ]

        # ä¸¦åˆ—å‡¦ç†
        tasks = [
            self._process_single_batch(batch, processor)
            for batch in batches
        ]

        batch_results = await asyncio.gather(*tasks, return_exceptions=True)

        # çµæœçµ±åˆ
        for batch_result in batch_results:
            if isinstance(batch_result, Exception):
                logger.error(f"Batch processing error: {batch_result}")
                continue
            results.extend(batch_result)

        return results
```

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- 80%ä»¥ä¸Šã®ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
- TDDå®Œå…¨å®Ÿè·µã®å®Ÿè£…
- ä¸¦åˆ—å‡¦ç†å¯¾å¿œã®é«˜æ€§èƒ½API
- å“è³ªã‚²ãƒ¼ãƒˆçµ±åˆ
- å®Œå…¨ãªCI/CDçµ±åˆ

````

### **æ¤œè¨¼æ–¹æ³•**
```bash
# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã¨ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
cd backend
pytest --cov=src --cov-report=html
open htmlcov/index.html

# å“è³ªãƒã‚§ãƒƒã‚¯
ruff check src/
mypy src/
bandit -r src/

# ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ
python -c "
import asyncio
from src.application.services.parallel_processor import ParallelProcessor

async def test():
    processor = ParallelProcessor(max_workers=4)
    items = list(range(100))
    results = await processor.process_batch(items, lambda x: x * 2)
    print(f'Processed {len(results)} items')

asyncio.run(test())
"
````

---

# Phase 5: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ§‹ç¯‰

## ğŸš€ **ç›®æ¨™**

Next.js 15.5 + React
19 ã«ã‚ˆã‚‹æœ€å…ˆç«¯ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç’°å¢ƒã®æ§‹ç¯‰ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å”èª¿ç·¨é›†æ©Ÿèƒ½ã®å®Ÿè£…åŸºç›¤æ•´å‚™ã€‚

## ğŸ“‹ **å‰ææ¡ä»¶**

### **å¿…é ˆãƒ„ãƒ¼ãƒ«ç¢ºèª**

```bash
# Node.js ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ20+å¿…é ˆï¼‰
node --version

# pnpm ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ8+å¿…é ˆï¼‰
pnpm --version

# TypeScript ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
pnpm tsc --version

# Next.js CLIç¢ºèª
pnpm next --version
```

## ğŸ”§ **Step 5.1: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:development:implement frontend-init --next 15.5 --react 19 --typescript --tailwind 4
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

```markdown
# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

Next.js 15.5 + React 19 + TypeScript + Tailwind CSS 4.0 ç’°å¢ƒã®æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š

#### frontend/package.json

{ "name": "autoforge-nexus-frontend", "version": "0.1.0", "private": true,
"scripts": { "dev": "next dev", "build": "next build", "start": "next start",
"lint": "next lint", "type-check": "tsc --noEmit", "test": "jest --watch",
"test:ci": "jest --ci", "test:e2e": "playwright test" }, "dependencies": {
"next": "15.5.0", "react": "19.0.0", "react-dom": "19.0.0", "typescript":
"5.6.3", "@clerk/nextjs": "^4.29.0", "zustand": "^4.5.0", "swr": "^2.2.5",
"@tanstack/react-query": "^5.20.0" }, "devDependencies": { "@types/react":
"19.0.0", "@types/react-dom": "19.0.0", "tailwindcss": "4.0.0", "autoprefixer":
"^10.4.17", "postcss": "^8.4.35", "eslint": "9.15.0", "eslint-config-next":
"15.5.0", "prettier": "3.3.3", "jest": "^29.7.0", "@testing-library/react":
"^14.2.0", "@playwright/test": "^1.48.0" } }

### TypeScriptè¨­å®š

#### frontend/tsconfig.json

{ "compilerOptions": { "target": "ES2022", "lib": ["dom", "dom.iterable",
"esnext"], "allowJs": true, "skipLibCheck": true, "strict": true,
"forceConsistentCasingInFileNames": true, "noEmit": true, "esModuleInterop":
true, "module": "esnext", "moduleResolution": "bundler", "resolveJsonModule":
true, "isolatedModules": true, "jsx": "preserve", "incremental": true,
"plugins": [ { "name": "next" } ], "paths": { "@/_": ["./src/_"] } }, "include":
["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"], "exclude":
["node_modules"] }

### Tailwind CSS 4.0è¨­å®š

#### frontend/tailwind.config.ts

import type { Config } from 'tailwindcss'

const config: Config = { content: [ './src/pages/**/*.{js,ts,jsx,tsx,mdx}',
'./src/components/**/*.{js,ts,jsx,tsx,mdx}',
'./src/app/**/*.{js,ts,jsx,tsx,mdx}', ], theme: { extend: { colors: { primary: {
50: '#f0f9ff', 500: '#3b82f6', 900: '#1e3a8a', }, secondary: { 50: '#faf5ff',
500: '#a855f7', 900: '#581c87', }, }, animation: { 'fade-in': 'fadeIn 0.5s
ease-in-out', 'slide-up': 'slideUp 0.3s ease-out', }, keyframes: { fadeIn: {
'0%': { opacity: '0' }, '100%': { opacity: '1' }, }, slideUp: { '0%': {
transform: 'translateY(10px)', opacity: '0' }, '100%': { transform:
'translateY(0)', opacity: '1' }, }, }, }, }, plugins: [], }

export default config

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- Next.js 15.5ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 
- TypeScriptå³å¯†è¨­å®š
- Tailwind CSS 4.0è¨­å®š
- é–‹ç™ºç’°å¢ƒã®å®Œå…¨æ§‹ç¯‰
```

### **æ¤œè¨¼æ–¹æ³•**

```bash
# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
cd frontend
pnpm install

# é–‹ç™ºã‚µãƒ¼ãƒãƒ¼èµ·å‹•
pnpm dev

# TypeScriptæ¤œè¨¼
pnpm type-check

# ãƒ“ãƒ«ãƒ‰ç¢ºèª
pnpm build
```

---

## ğŸ”§ **Step 5.2: UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:ui-ux-designer design-system --shadcn --accessible --responsive
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

```markdown
# UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

shadcn/ui ãƒ™ãƒ¼ã‚¹ã®ã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã§ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãªãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### shadcn/uiè¨­å®š

# frontend/components.json

{ "$schema": "https://ui.shadcn.com/schema.json", "style": "default", "rsc":
true, "tsx": true, "tailwind": { "config": "tailwind.config.ts", "css":
"src/app/globals.css", "baseColor": "slate", "cssVariables": true, "prefix": ""
}, "aliases": { "components": "@/components", "utils": "@/lib/utils" } }

### åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š

# frontend/src/app/globals.css

@tailwind base; @tailwind components; @tailwind utilities;

@layer base { :root { --background: 0 0% 100%; --foreground: 222.2 84% 4.9%;
--card: 0 0% 100%; --card-foreground: 222.2 84% 4.9%; --popover: 0 0% 100%;
--popover-foreground: 222.2 84% 4.9%; --primary: 221.2 83.2% 53.3%;
--primary-foreground: 210 40% 98%; --secondary: 210 40% 96.1%;
--secondary-foreground: 222.2 47.4% 11.2%; --muted: 210 40% 96.1%;
--muted-foreground: 215.4 16.3% 46.9%; --accent: 210 40% 96.1%;
--accent-foreground: 222.2 47.4% 11.2%; --destructive: 0 84.2% 60.2%;
--destructive-foreground: 210 40% 98%; --border: 214.3 31.8% 91.4%; --input:
214.3 31.8% 91.4%; --ring: 221.2 83.2% 53.3%; --radius: 0.5rem; }

.dark { --background: 222.2 84% 4.9%; --foreground: 210 40% 98%; --card: 222.2
84% 4.9%; --card-foreground: 210 40% 98%; --popover: 222.2 84% 4.9%;
--popover-foreground: 210 40% 98%; --primary: 217.2 91.2% 59.8%;
--primary-foreground: 222.2 47.4% 11.2%; --secondary: 217.2 32.6% 17.5%;
--secondary-foreground: 210 40% 98%; --muted: 217.2 32.6% 17.5%;
--muted-foreground: 215 20.2% 65.1%; --accent: 217.2 32.6% 17.5%;
--accent-foreground: 210 40% 98%; --destructive: 0 62.8% 30.6%;
--destructive-foreground: 210 40% 98%; --border: 217.2 32.6% 17.5%; --input:
217.2 32.6% 17.5%; --ring: 224.3 76.3% 48%; } }

### ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°

# frontend/src/lib/utils.ts

import { type ClassValue, clsx } from "clsx" import { twMerge } from
"tailwind-merge"

export function cn(...inputs: ClassValue[]) { return twMerge(clsx(inputs)) }

### Storybookã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

# frontend/.storybook/main.ts

import type { StorybookConfig } from "@storybook/nextjs"

const config: StorybookConfig = { stories:
["../src/**/*.stories.@(js|jsx|ts|tsx|mdx)"], addons: [
"@storybook/addon-links", "@storybook/addon-essentials",
"@storybook/addon-interactions", "@storybook/addon-a11y" ], framework: { name:
"@storybook/nextjs", options: {}, }, }

export default config

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- shadcn/uiçµ±åˆ
- ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£å¯¾å¿œ
- ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³
- Storybookç’°å¢ƒ
- ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œ
```

### **æ¤œè¨¼æ–¹æ³•**

```bash
# shadcn/ui CLIã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pnpm dlx shadcn-ui@latest init

# ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¿½åŠ ä¾‹
pnpm dlx shadcn-ui@latest add button
pnpm dlx shadcn-ui@latest add card
pnpm dlx shadcn-ui@latest add form

# Storybookèµ·å‹•
pnpm storybook

# ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
pnpm exec pa11y http://localhost:3000
```

---

# Phase 6: çµ±åˆãƒ»å“è³ªä¿è¨¼

## ğŸš€ **ç›®æ¨™**

ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®å“è³ªåŸºæº–ã‚’æº€ãŸã™çµ±åˆãƒ†ã‚¹ãƒˆã€CI/CDã€ç›£è¦–ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç’°å¢ƒã®å®Œå…¨æ§‹ç¯‰ã€‚

## ğŸ“‹ **å‰ææ¡ä»¶**

### **å¿…é ˆãƒ„ãƒ¼ãƒ«ç¢ºèª**

```bash
# Docker ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ24+å¿…é ˆï¼‰
docker --version
docker-compose --version

# GitHub CLIç¢ºèª
gh --version

# è² è·ãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ«ç¢ºèª
locust --version 2>/dev/null || echo "Locust not installed"
k6 version 2>/dev/null || echo "K6 not installed"

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ„ãƒ¼ãƒ«ç¢ºèª
trivy --version 2>/dev/null || echo "Trivy not installed"
```

## ğŸ”§ **Step 6.1: çµ±åˆãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:quality:tdd test-environment --e2e playwright --api pytest --frontend jest --coverage 80
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

```markdown
# çµ±åˆãƒ†ã‚¹ãƒˆç’°å¢ƒæ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

E2Eã€APIã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆç’°å¢ƒæ§‹ç¯‰ï¼ˆ80%ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™ï¼‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### E2Eãƒ†ã‚¹ãƒˆè¨­å®šï¼ˆPlaywrightï¼‰

#### tests/e2e/playwright.config.ts

import { defineConfig, devices } from '@playwright/test';

export default defineConfig({ testDir: './e2e', fullyParallel: true, forbidOnly:
!!process.env.CI, retries: process.env.CI ? 2 : 0, workers: process.env.CI ? 1 :
undefined, reporter: 'html', use: { baseURL: 'http://localhost:3000', trace:
'on-first-retry', }, projects: [ { name: 'chromium', use: { ...devices['Desktop
Chrome'] } }, { name: 'firefox', use: { ...devices['Desktop Firefox'] } }, {
name: 'webkit', use: { ...devices['Desktop Safari'] } }, ], webServer: {
command: 'npm run dev', url: 'http://localhost:3000', reuseExistingServer:
!process.env.CI, }, });

### APIçµ±åˆãƒ†ã‚¹ãƒˆè¨­å®šï¼ˆpytestï¼‰

#### backend/pytest.ini

[tool:pytest] minversion = 6.0 addopts = -ra -q --strict-markers --cov=src
--cov-report=html --cov-report=term-missing:skip-covered --cov-fail-under=80
testpaths = tests python*files = test*_.py python_classes = Test_
python*functions = test*\*

### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆè¨­å®šï¼ˆJestï¼‰

#### frontend/jest.config.js

const nextJest = require('next/jest')

const createJestConfig = nextJest({ dir: './', })

const customJestConfig = { setupFilesAfterEnv: ['<rootDir>/jest.setup.js'],
moduleNameMapper: { '^@/(._)$': '<rootDir>/src/$1', }, testEnvironment:
'jest-environment-jsdom', collectCoverageFrom: [ 'src/\*\*/_.{js,jsx,ts,tsx}',
'!src/**/\*.d.ts', '!src/**/\*.stories.{js,jsx,ts,tsx}', ], coverageThreshold: {
global: { branches: 75, functions: 75, lines: 75, statements: 75 } } }

module.exports = createJestConfig(customJestConfig)

### Docker Composeãƒ†ã‚¹ãƒˆç’°å¢ƒ

#### docker-compose.test.yml

version: '3.8'

services: test-db: image: postgres:16-alpine environment: POSTGRES_DB: test_db
POSTGRES_USER: test_user POSTGRES_PASSWORD: test_pass healthcheck: test:
["CMD-SHELL", "pg_isready -U test_user"] interval: 5s timeout: 5s retries: 5

test-redis: image: redis:7-alpine healthcheck: test: ["CMD", "redis-cli",
"ping"] interval: 5s timeout: 5s retries: 5

test-backend: build: ./backend environment: DATABASE_URL:
postgresql://test_user:test_pass@test-db:5432/test_db REDIS_URL:
redis://test-redis:6379 TESTING: "true" depends_on: test-db: condition:
service_healthy test-redis: condition: service_healthy volumes: - ./backend:/app
command: pytest

test-frontend: build: ./frontend environment: NEXT_PUBLIC_API_URL:
http://test-backend:8000 volumes: - ./frontend:/app command: npm run test:ci

### Makefileçµ±åˆ

#### Makefile

.PHONY: test test-unit test-integration test-e2e test-all

test-env-up: docker-compose -f docker-compose.test.yml up -d

test-env-down: docker-compose -f docker-compose.test.yml down -v

test-unit: cd backend && pytest tests/unit --cov=src cd frontend && npm run
test:unit

test-integration: docker-compose -f docker-compose.test.yml run --rm
test-backend docker-compose -f docker-compose.test.yml run --rm test-frontend

test-e2e: npx playwright test

test-all: test-env-up test-unit test-integration test-e2e test-env-down

test-coverage: cd backend && pytest --cov=src --cov-report=html cd frontend &&
npm run test:coverage @echo "Backend coverage: htmlcov/index.html" @echo
"Frontend coverage: coverage/index.html"

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- å®Œå…¨ãªãƒ†ã‚¹ãƒˆç’°å¢ƒ
- 80%+ã®ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸
- E2E/API/UIçµ±åˆãƒ†ã‚¹ãƒˆ
- Docker Composeãƒ†ã‚¹ãƒˆç’°å¢ƒ
- CIçµ±åˆå¯èƒ½ãªè¨­å®š
```

### **æ¤œè¨¼æ–¹æ³•**

```bash
# ãƒ†ã‚¹ãƒˆç’°å¢ƒèµ·å‹•
make test-env-up

# å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
make test-all

# ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
make test-coverage

# E2E ãƒ†ã‚¹ãƒˆã®ã¿
npx playwright test --headed
```

---

## ğŸ”§ **Step 6.2: CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:operations:deploy ci-cd --github-actions --cloudflare --multi-stage
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

````markdown
# ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

libSQL Vector ã‚’ä½¿ç”¨ã—ãŸ1536æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### 1. libSQL Vectorè¨­å®š

```sql
-- backend/migrations/001_create_vector_tables.sql
-- libSQL Vector æ‹¡å¼µã®æœ‰åŠ¹åŒ–
PRAGMA vector_enable = 1;

-- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåŸ‹ã‚è¾¼ã¿ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE prompt_embeddings (
    id TEXT PRIMARY KEY,
    prompt_id TEXT NOT NULL,
    embedding VECTOR(1536) NOT NULL,
    model_name TEXT NOT NULL DEFAULT 'text-embedding-ada-002',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (prompt_id) REFERENCES prompts(id)
);

-- HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
CREATE INDEX prompt_embeddings_hnsw_idx ON prompt_embeddings(embedding)
USING HNSW
WITH (
    m = 16,
    ef_construction = 200,
    ef_search = 50
);

-- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX prompt_embeddings_prompt_id_idx ON prompt_embeddings(prompt_id);
CREATE INDEX prompt_embeddings_model_idx ON prompt_embeddings(model_name);
```
````

### 2. åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹

```python
# backend/src/infrastructure/embeddings/embedding_service.py
from typing import List, Dict, Any
import asyncio
import numpy as np
from openai import AsyncOpenAI
from sqlalchemy.ext.asyncio import AsyncSession

class EmbeddingService:
    def __init__(self, openai_client: AsyncOpenAI, session: AsyncSession):
        self._client = openai_client
        self._session = session
        self._model = "text-embedding-ada-002"
        self._dimension = 1536

    async def generate_embedding(self, text: str) -> List[float]:
        """å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"""
        try:
            response = await self._client.embeddings.create(
                input=text,
                model=self._model
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Failed to generate embedding: {e}")
            raise

    async def generate_embeddings_batch(
        self,
        texts: List[str],
        batch_size: int = 100
    ) -> List[List[float]]:
        """ãƒãƒƒãƒåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"""
        embeddings = []

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]

            try:
                response = await self._client.embeddings.create(
                    input=batch,
                    model=self._model
                )

                batch_embeddings = [data.embedding for data in response.data]
                embeddings.extend(batch_embeddings)

                # APIåˆ¶é™ã‚’è€ƒæ…®ã—ãŸå¾…æ©Ÿ
                if len(batch) == batch_size:
                    await asyncio.sleep(0.1)

            except Exception as e:
                logger.error(f"Failed to generate batch embeddings: {e}")
                # å€‹åˆ¥å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                for text in batch:
                    try:
                        embedding = await self.generate_embedding(text)
                        embeddings.append(embedding)
                    except:
                        embeddings.append([0.0] * self._dimension)

        return embeddings

    async def save_embedding(
        self,
        prompt_id: str,
        text: str,
        embedding: List[float]
    ) -> None:
        """åŸ‹ã‚è¾¼ã¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        await self._session.execute(
            text("""
                INSERT INTO prompt_embeddings
                (id, prompt_id, embedding, model_name)
                VALUES (?, ?, ?, ?)
            """),
            (
                str(uuid4()),
                prompt_id,
                np.array(embedding).tobytes(),
                self._model
            )
        )
        await self._session.commit()
```

### 3. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢å®Ÿè£…

```python
# backend/src/infrastructure/search/vector_search.py
from typing import List, Tuple, Dict, Optional
import numpy as np
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text

from ...domain.search.value_objects import SearchResult, SimilarityScore

class VectorSearchService:
    def __init__(self, session: AsyncSession, embedding_service: EmbeddingService):
        self._session = session
        self._embedding_service = embedding_service

    async def similarity_search(
        self,
        query: str,
        limit: int = 10,
        min_similarity: float = 0.7,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[SearchResult]:
        """é¡ä¼¼åº¦æ¤œç´¢å®Ÿè¡Œ"""

        # ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        query_embedding = await self._embedding_service.generate_embedding(query)

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶æ§‹ç¯‰
        filter_clause = ""
        filter_params = []

        if filters:
            conditions = []
            if "user_id" in filters:
                conditions.append("p.user_id = ?")
                filter_params.append(filters["user_id"])
            if "tags" in filters:
                conditions.append("EXISTS (SELECT 1 FROM prompt_tags pt WHERE pt.prompt_id = p.id AND pt.tag IN ?)")
                filter_params.append(tuple(filters["tags"]))

            if conditions:
                filter_clause = "AND " + " AND ".join(conditions)

        # ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦æ¤œç´¢
        query_sql = f"""
            SELECT
                p.id,
                p.title,
                p.content,
                p.user_id,
                p.created_at,
                pe.embedding <-> ? as similarity_score
            FROM prompt_embeddings pe
            JOIN prompts p ON pe.prompt_id = p.id
            WHERE pe.embedding <-> ? < ?
            {filter_clause}
            ORDER BY similarity_score ASC
            LIMIT ?
        """

        params = [
            np.array(query_embedding).tobytes(),
            np.array(query_embedding).tobytes(),
            1.0 - min_similarity,  # è·é›¢ã‚’é¡ä¼¼åº¦ã«å¤‰æ›
            *filter_params,
            limit
        ]

        result = await self._session.execute(text(query_sql), params)
        rows = result.fetchall()

        search_results = []
        for row in rows:
            similarity = 1.0 - row.similarity_score  # è·é›¢ã‚’é¡ä¼¼åº¦ã«æˆ»ã™

            search_results.append(SearchResult(
                prompt_id=row.id,
                title=row.title,
                content=row.content[:200] + "..." if len(row.content) > 200 else row.content,
                user_id=row.user_id,
                similarity_score=SimilarityScore(similarity),
                created_at=row.created_at
            ))

        return search_results

    async def hybrid_search(
        self,
        query: str,
        limit: int = 10,
        vector_weight: float = 0.7,
        text_weight: float = 0.3,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[SearchResult]:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ« + ãƒ†ã‚­ã‚¹ãƒˆï¼‰"""

        # ä¸¦åˆ—ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ã‚’å®Ÿè¡Œ
        vector_results, text_results = await asyncio.gather(
            self.similarity_search(query, limit * 2, filters=filters),
            self._text_search(query, limit * 2, filters=filters)
        )

        # ã‚¹ã‚³ã‚¢æ­£è¦åŒ–ã¨çµ±åˆ
        combined_scores = {}

        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœ
        for i, result in enumerate(vector_results):
            score = (1 - i / len(vector_results)) * vector_weight
            combined_scores[result.prompt_id] = {
                'result': result,
                'score': score,
                'vector_score': result.similarity_score.value
            }

        # ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢çµæœ
        for i, result in enumerate(text_results):
            score = (1 - i / len(text_results)) * text_weight
            if result.prompt_id in combined_scores:
                combined_scores[result.prompt_id]['score'] += score
            else:
                combined_scores[result.prompt_id] = {
                    'result': result,
                    'score': score,
                    'vector_score': 0.0
                }

        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        sorted_results = sorted(
            combined_scores.values(),
            key=lambda x: x['score'],
            reverse=True
        )

        return [item['result'] for item in sorted_results[:limit]]
```

### 4. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–

```python
# backend/src/infrastructure/search/index_optimizer.py
from typing import Dict, Any
import asyncio
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text

class IndexOptimizer:
    def __init__(self, session: AsyncSession):
        self._session = session

    async def optimize_hnsw_index(self, table_name: str = "prompt_embeddings") -> Dict[str, Any]:
        """HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æœ€é©åŒ–"""

        # ç¾åœ¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆå–å¾—
        stats_before = await self._get_index_stats(table_name)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰
        await self._session.execute(text(f"""
            REINDEX prompt_embeddings_hnsw_idx
        """))

        # æœ€é©åŒ–å¾Œã®çµ±è¨ˆå–å¾—
        stats_after = await self._get_index_stats(table_name)

        # VACUUMå®Ÿè¡Œï¼ˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æœ€é©åŒ–ï¼‰
        await self._session.execute(text("VACUUM"))

        await self._session.commit()

        return {
            "before": stats_before,
            "after": stats_after,
            "improvement": {
                "size_reduction": stats_before["size"] - stats_after["size"],
                "search_time_improvement": stats_before["avg_search_time"] - stats_after["avg_search_time"]
            }
        }

    async def _get_index_stats(self, table_name: str) -> Dict[str, Any]:
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆæƒ…å ±å–å¾—"""
        result = await self._session.execute(text(f"""
            SELECT
                COUNT(*) as record_count,
                AVG(LENGTH(embedding)) as avg_embedding_size
            FROM {table_name}
        """))

        row = result.fetchone()

        return {
            "record_count": row.record_count,
            "avg_embedding_size": row.avg_embedding_size,
            "size": row.record_count * row.avg_embedding_size,
            "avg_search_time": 0.0  # å®Ÿæ¸¬å€¤ã§æ›´æ–°
        }
```

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- libSQL Vector å®Œå…¨è¨­å®š
- 1536æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿ã‚·ã‚¹ãƒ†ãƒ 
- HNSWé«˜é€Ÿæ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
- ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢æ©Ÿèƒ½
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–æ©Ÿèƒ½

````

### **æ¤œè¨¼æ–¹æ³•**
```bash
# ãƒ™ã‚¯ãƒˆãƒ«DBæ¥ç¶šç¢ºèª
python -c "
import sqlite3
conn = sqlite3.connect('autoforge.db')
cursor = conn.cursor()
cursor.execute('PRAGMA vector_enable')
result = cursor.fetchone()
print(f'Vector enabled: {result[0]}')
"

# åŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ
cd backend
python -c "
import asyncio
from src.infrastructure.embeddings.embedding_service import EmbeddingService

async def test():
    service = EmbeddingService(openai_client, session)
    embedding = await service.generate_embedding('Test prompt')
    print(f'Embedding dimension: {len(embedding)}')

asyncio.run(test())
"

# æ¤œç´¢ãƒ†ã‚¹ãƒˆ
python -c "
import asyncio
from src.infrastructure.search.vector_search import VectorSearchService

async def test():
    search = VectorSearchService(session, embedding_service)
    results = await search.similarity_search('machine learning prompt', limit=5)
    print(f'Found {len(results)} similar prompts')

asyncio.run(test())
"
````

---

## ğŸ”§ **Step 4.2: ãƒ‡ãƒ¼ã‚¿ç®¡ç†åŸºç›¤**

### **ã‚³ãƒãƒ³ãƒ‰**

```bash
/ai:development:implement data-layer --tdd --coverage 85
```

### **AI ã¸ã®è©³ç´°æŒ‡ç¤º**

````markdown
# ãƒ‡ãƒ¼ã‚¿ç®¡ç†åŸºç›¤æ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

85%ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ç›®æ¨™ã¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ç®¡ç†å±¤ã®å®Œå…¨å®Ÿè£…

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«å®šç¾©

```python
# backend/src/infrastructure/models/prompt_models.py
from sqlalchemy import Column, String, Text, DateTime, Boolean, Float, ForeignKey
from sqlalchemy.dialects.sqlite import BLOB
from sqlalchemy.orm import relationship
from sqlalchemy.ext.declarative import declarative_base
from uuid import uuid4
from datetime import datetime

Base = declarative_base()

class PromptModel(Base):
    __tablename__ = "prompts"

    id = Column(String, primary_key=True, default=lambda: str(uuid4()))
    user_id = Column(String, nullable=False)
    title = Column(String(200), nullable=False)
    content = Column(Text, nullable=False)
    description = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    published = Column(Boolean, default=False)
    archived = Column(Boolean, default=False)
    quality_score = Column(Float)

    # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    versions = relationship("PromptVersionModel", back_populates="prompt")
    embeddings = relationship("PromptEmbeddingModel", back_populates="prompt")
    evaluations = relationship("EvaluationModel", back_populates="prompt")

    def to_entity(self) -> 'Prompt':
        from ...domain.prompt.entities import Prompt
        from ...domain.prompt.value_objects import PromptContent

        return Prompt(
            id=UUID(self.id),
            user_id=UUID(self.user_id),
            content=PromptContent(self.content),
            title=self.title,
            description=self.description,
            created_at=self.created_at,
            updated_at=self.updated_at
        )

    @classmethod
    def from_entity(cls, prompt: 'Prompt') -> 'PromptModel':
        return cls(
            id=str(prompt.id),
            user_id=str(prompt.user_id),
            title=prompt.title,
            content=prompt.content.value,
            description=prompt.description,
            created_at=prompt.created_at,
            updated_at=prompt.updated_at
        )

class PromptEmbeddingModel(Base):
    __tablename__ = "prompt_embeddings"

    id = Column(String, primary_key=True, default=lambda: str(uuid4()))
    prompt_id = Column(String, ForeignKey("prompts.id"), nullable=False)
    embedding = Column(BLOB, nullable=False)  # Vector stored as blob
    model_name = Column(String(100), nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)

    prompt = relationship("PromptModel", back_populates="embeddings")
```
````

### 2. ãƒªãƒã‚¸ãƒˆãƒªå®Ÿè£…

```python
# backend/src/infrastructure/repositories/prompt_repository.py
from typing import List, Optional
from uuid import UUID
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, or_, func
from sqlalchemy.orm import selectinload

from ...domain.prompt.entities import Prompt
from ...domain.prompt.repositories import PromptRepository
from ...domain.search.specifications import PromptSearchSpec
from ..models.prompt_models import PromptModel

class SQLAlchemyPromptRepository(PromptRepository):
    def __init__(self, session: AsyncSession):
        self._session = session

    async def save(self, prompt: Prompt) -> None:
        existing = await self._session.execute(
            select(PromptModel).where(PromptModel.id == str(prompt.id))
        )
        existing_model = existing.scalar_one_or_none()

        if existing_model:
            # æ›´æ–°
            existing_model.title = prompt.title
            existing_model.content = prompt.content.value
            existing_model.description = prompt.description
            existing_model.updated_at = prompt.updated_at
        else:
            # æ–°è¦ä½œæˆ
            model = PromptModel.from_entity(prompt)
            self._session.add(model)

        await self._session.commit()

    async def get_by_id(self, prompt_id: UUID) -> Optional[Prompt]:
        result = await self._session.execute(
            select(PromptModel)
            .options(selectinload(PromptModel.versions))
            .where(PromptModel.id == str(prompt_id))
        )
        model = result.scalar_one_or_none()
        return model.to_entity() if model else None

    async def get_by_user_id(
        self,
        user_id: UUID,
        limit: int = 50,
        offset: int = 0
    ) -> List[Prompt]:
        result = await self._session.execute(
            select(PromptModel)
            .where(PromptModel.user_id == str(user_id))
            .where(PromptModel.archived == False)
            .order_by(PromptModel.updated_at.desc())
            .limit(limit)
            .offset(offset)
        )
        return [model.to_entity() for model in result.scalars()]

    async def search(self, spec: PromptSearchSpec) -> List[Prompt]:
        query = select(PromptModel).where(PromptModel.archived == False)

        # ä»•æ§˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if spec.user_id:
            query = query.where(PromptModel.user_id == str(spec.user_id))

        if spec.title_contains:
            query = query.where(
                PromptModel.title.ilike(f"%{spec.title_contains}%")
            )

        if spec.content_contains:
            query = query.where(
                PromptModel.content.ilike(f"%{spec.content_contains}%")
            )

        if spec.published is not None:
            query = query.where(PromptModel.published == spec.published)

        if spec.quality_min:
            query = query.where(PromptModel.quality_score >= spec.quality_min)

        # ä¸¦ã³é †
        if spec.order_by == "created_at":
            query = query.order_by(PromptModel.created_at.desc())
        elif spec.order_by == "quality":
            query = query.order_by(PromptModel.quality_score.desc())
        else:
            query = query.order_by(PromptModel.updated_at.desc())

        query = query.limit(spec.limit).offset(spec.offset)

        result = await self._session.execute(query)
        return [model.to_entity() for model in result.scalars()]

    async def delete(self, prompt_id: UUID) -> None:
        await self._session.execute(
            select(PromptModel).where(PromptModel.id == str(prompt_id))
        )
        # ã‚½ãƒ•ãƒˆãƒ‡ãƒªãƒ¼ãƒˆ
        model = await self.get_by_id(prompt_id)
        if model:
            await self._session.execute(
                update(PromptModel)
                .where(PromptModel.id == str(prompt_id))
                .values(archived=True)
            )
            await self._session.commit()
```

### 3. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç®¡ç†

```python
# backend/src/infrastructure/data/consistency_manager.py
from typing import List, Dict, Any
import asyncio
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text, select
import logging

logger = logging.getLogger(__name__)

class DataConsistencyManager:
    def __init__(self, session: AsyncSession):
        self._session = session

    async def check_referential_integrity(self) -> Dict[str, Any]:
        """å‚ç…§æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        issues = []

        # å­¤ç«‹ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåŸ‹ã‚è¾¼ã¿ãƒã‚§ãƒƒã‚¯
        result = await self._session.execute(text("""
            SELECT pe.id, pe.prompt_id
            FROM prompt_embeddings pe
            LEFT JOIN prompts p ON pe.prompt_id = p.id
            WHERE p.id IS NULL
        """))

        orphaned_embeddings = result.fetchall()
        if orphaned_embeddings:
            issues.append({
                "type": "orphaned_embeddings",
                "count": len(orphaned_embeddings),
                "items": [{"id": row.id, "prompt_id": row.prompt_id} for row in orphaned_embeddings]
            })

        # åŸ‹ã‚è¾¼ã¿ãŒãªã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒã‚§ãƒƒã‚¯
        result = await self._session.execute(text("""
            SELECT p.id, p.title
            FROM prompts p
            LEFT JOIN prompt_embeddings pe ON p.id = pe.prompt_id
            WHERE pe.prompt_id IS NULL
            AND p.archived = FALSE
        """))

        prompts_without_embeddings = result.fetchall()
        if prompts_without_embeddings:
            issues.append({
                "type": "prompts_without_embeddings",
                "count": len(prompts_without_embeddings),
                "items": [{"id": row.id, "title": row.title} for row in prompts_without_embeddings]
            })

        return {
            "status": "healthy" if not issues else "issues_found",
            "issues": issues,
            "checked_at": datetime.utcnow()
        }

    async def repair_data_consistency(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ä¿®å¾©"""
        repair_log = []

        # å­¤ç«‹ã—ãŸåŸ‹ã‚è¾¼ã¿ã‚’å‰Šé™¤
        result = await self._session.execute(text("""
            DELETE FROM prompt_embeddings
            WHERE prompt_id NOT IN (SELECT id FROM prompts)
        """))
        if result.rowcount > 0:
            repair_log.append(f"Deleted {result.rowcount} orphaned embeddings")

        # åŸ‹ã‚è¾¼ã¿ãŒãªã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        result = await self._session.execute(text("""
            SELECT id, content
            FROM prompts
            WHERE id NOT IN (SELECT DISTINCT prompt_id FROM prompt_embeddings)
            AND archived = FALSE
        """))

        prompts_to_embed = result.fetchall()
        if prompts_to_embed:
            # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            for row in prompts_to_embed:
                await self._add_embedding_task(row.id, row.content)

            repair_log.append(f"Queued {len(prompts_to_embed)} prompts for embedding generation")

        await self._session.commit()

        return {
            "repairs_completed": len(repair_log),
            "repair_log": repair_log,
            "repaired_at": datetime.utcnow()
        }

    async def _add_embedding_task(self, prompt_id: str, content: str) -> None:
        """åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ """
        # Redis Queueã¾ãŸã¯åŒç­‰ã®ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        pass
```

### 4. ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

```python
# backend/src/infrastructure/migrations/migration_manager.py
from typing import List, Dict, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
import logging

logger = logging.getLogger(__name__)

class MigrationManager:
    def __init__(self, session: AsyncSession):
        self._session = session
        self._migrations = [
            self._migration_001_initial_schema,
            self._migration_002_add_embeddings,
            self._migration_003_add_evaluations,
            self._migration_004_optimize_indexes
        ]

    async def run_migrations(self) -> Dict[str, Any]:
        """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        results = []

        # ç¾åœ¨ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
        current_version = await self._get_current_version()

        for i, migration in enumerate(self._migrations):
            migration_version = i + 1

            if migration_version <= current_version:
                continue

            try:
                logger.info(f"Running migration {migration_version}")
                await migration()
                await self._set_version(migration_version)
                results.append({
                    "version": migration_version,
                    "status": "success",
                    "name": migration.__name__
                })
                logger.info(f"Migration {migration_version} completed")

            except Exception as e:
                logger.error(f"Migration {migration_version} failed: {e}")
                results.append({
                    "version": migration_version,
                    "status": "failed",
                    "name": migration.__name__,
                    "error": str(e)
                })
                break

        return {
            "migrations_run": len([r for r in results if r["status"] == "success"]),
            "results": results,
            "current_version": await self._get_current_version()
        }

    async def _migration_001_initial_schema(self) -> None:
        """åˆæœŸã‚¹ã‚­ãƒ¼ãƒä½œæˆ"""
        await self._session.execute(text("""
            CREATE TABLE IF NOT EXISTS prompts (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                description TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                published BOOLEAN DEFAULT FALSE,
                archived BOOLEAN DEFAULT FALSE,
                quality_score REAL
            )
        """))

        await self._session.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_prompts_user_id ON prompts(user_id)
        """))

        await self._session.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_prompts_created_at ON prompts(created_at DESC)
        """))

    async def _migration_002_add_embeddings(self) -> None:
        """åŸ‹ã‚è¾¼ã¿ãƒ†ãƒ¼ãƒ–ãƒ«è¿½åŠ """
        # libSQL Vectoræ‹¡å¼µã‚’æœ‰åŠ¹åŒ–
        await self._session.execute(text("PRAGMA vector_enable = 1"))

        await self._session.execute(text("""
            CREATE TABLE IF NOT EXISTS prompt_embeddings (
                id TEXT PRIMARY KEY,
                prompt_id TEXT NOT NULL,
                embedding VECTOR(1536) NOT NULL,
                model_name TEXT NOT NULL DEFAULT 'text-embedding-ada-002',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (prompt_id) REFERENCES prompts(id)
            )
        """))

        await self._session.execute(text("""
            CREATE INDEX IF NOT EXISTS prompt_embeddings_hnsw_idx
            ON prompt_embeddings(embedding)
            USING HNSW
            WITH (m = 16, ef_construction = 200, ef_search = 50)
        """))

    async def _get_current_version(self) -> int:
        """ç¾åœ¨ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—"""
        try:
            result = await self._session.execute(text("""
                SELECT version FROM schema_migrations ORDER BY version DESC LIMIT 1
            """))
            row = result.fetchone()
            return row.version if row else 0
        except:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            await self._session.execute(text("""
                CREATE TABLE IF NOT EXISTS schema_migrations (
                    version INTEGER PRIMARY KEY,
                    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            return 0
```

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ç®¡ç†åŸºç›¤
- 85%ä»¥ä¸Šã®ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
- ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
- è‡ªå‹•ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½
- é«˜æ€§èƒ½ãªãƒªãƒã‚¸ãƒˆãƒªãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè£…

````

### **æ¤œè¨¼æ–¹æ³•**
```bash
# ãƒ‡ãƒ¼ã‚¿å±¤ãƒ†ã‚¹ãƒˆ
cd backend
pytest src/tests/infrastructure/repositories/ --cov=src.infrastructure --cov-report=html

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
python -c "
import asyncio
from src.infrastructure.migrations.migration_manager import MigrationManager

async def test():
    manager = MigrationManager(session)
    result = await manager.run_migrations()
    print(f'Migrations completed: {result}')

asyncio.run(test())
"

# ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
python -c "
import asyncio
from src.infrastructure.data.consistency_manager import DataConsistencyManager

async def test():
    manager = DataConsistencyManager(session)
    result = await manager.check_referential_integrity()
    print(f'Consistency status: {result[\"status\"]}')

asyncio.run(test())
"
````

---

<function_calls> <invoke name="TodoWrite"> <parameter name="todos">[{"content":
"ç’°å¢ƒæ§‹ç¯‰å®Œå…¨ã‚¬ã‚¤ãƒ‰ã®æ§‹é€ è¨­è¨ˆã¨åŸºæœ¬ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ", "status": "completed",
"activeForm": "ç’°å¢ƒæ§‹ç¯‰ã‚¬ã‚¤ãƒ‰æ§‹é€ è¨­è¨ˆå®Œäº†"}, {"content": "Phase 1:
Gitãƒ»åŸºç›¤ç’°å¢ƒæ§‹ç¯‰ã®è©³ç´°æ‰‹é †æ›¸ä½œæˆ", "status": "completed", "activeForm":
"GitåŸºç›¤ç’°å¢ƒæ‰‹é †æ›¸ä½œæˆå®Œäº†"}, {"content": "Phase 2:
ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»DevOpsç’°å¢ƒæ§‹ç¯‰ã®è©³ç´°æ‰‹é †æ›¸ä½œæˆ", "status": "completed", "activeForm":
"ã‚¤ãƒ³ãƒ•ãƒ©DevOpsæ‰‹é †æ›¸ä½œæˆå®Œäº†"}, {"content": "Phase 3:
ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ§‹ç¯‰ã®è©³ç´°æ‰‹é †æ›¸ä½œæˆ", "status": "in_progress", "activeForm":
"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ‰‹é †æ›¸ä½œæˆä¸­"}, {"content": "Phase 4:
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ™ã‚¯ãƒˆãƒ«ç’°å¢ƒã®è©³ç´°æ‰‹é †æ›¸ä½œæˆ", "status": "pending", "activeForm":
"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç’°å¢ƒæ‰‹é †æ›¸ä½œæˆå¾…ã¡"}, {"content": "Phase 5:
ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ§‹ç¯‰ã®è©³ç´°æ‰‹é †æ›¸ä½œæˆ", "status": "pending", "activeForm":
"ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç’°å¢ƒæ‰‹é †æ›¸ä½œæˆå¾…ã¡"}, {"content": "Phase 6:
çµ±åˆãƒ»å“è³ªä¿è¨¼ã®è©³ç´°æ‰‹é †æ›¸ä½œæˆ", "status": "pending", "activeForm":
"çµ±åˆå“è³ªä¿è¨¼æ‰‹é †æ›¸ä½œæˆå¾…ã¡"}, {"content": "ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰ã¨
FAQä½œæˆ", "status": "pending", "activeForm":
"ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰ä½œæˆå¾…ã¡"}]
