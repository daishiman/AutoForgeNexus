# Phase 6: çµ±åˆãƒ»å“è³ªä¿è¨¼ - ç’°å¢ƒæ§‹ç¯‰è©³ç´°ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ æ¦‚è¦

AutoForgeNexus ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã® Phase
6 ã¯ã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®å“è³ªä¿è¨¼ç’°å¢ƒã‚’æ§‹ç¯‰ã™ã‚‹æœ€çµ‚ãƒ•ã‚§ãƒ¼ã‚ºã§ã™ã€‚çµ±åˆãƒ†ã‚¹ãƒˆã€CI/CDã€ç›£è¦–ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®å®Œå…¨ãªç’°å¢ƒã‚’æ•´å‚™ã—ã¾ã™ã€‚

---

## ğŸ”§ Step 6.1: çµ±åˆãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### ã‚³ãƒãƒ³ãƒ‰

```bash
/ai:quality:tdd test-env --playwright --pytest --jest --coverage 80 --docker
```

### **èµ·å‹•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**

Phase 6 Step 6.1 ã§èµ·å‹•ã•ã‚Œã‚‹ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼š

- **qa-coordinator Agent**
  (ãƒªãƒ¼ãƒ€ãƒ¼): çµ±åˆãƒ†ã‚¹ãƒˆç’°å¢ƒå…¨ä½“ã®è¨­è¨ˆã¨å“è³ªä¿è¨¼æˆ¦ç•¥ã®çµ±æ‹¬
- **test-automation-engineer
  Agent**: ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã®å®Ÿè£…
- **backend-developer Agent**: API ãƒ†ã‚¹ãƒˆç’°å¢ƒã¨ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã®æ§‹ç¯‰
- **frontend-architect Agent**: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ E2E ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ§‹ç¯‰
- **edge-database-administrator
  Agent**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç’°å¢ƒã¨ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã®è¨­å®š

### AI ã¸ã®è©³ç´°æŒ‡ç¤º

````markdown
# çµ±åˆãƒ†ã‚¹ãƒˆç’°å¢ƒæ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

Playwright, pytest, Jest ã‚’ä½¿ç”¨ã—ãŸåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### E2E ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— (Playwright)

#### frontend/playwright.config.ts

```typescript
import { defineConfig, devices } from '@playwright/test';

export default defineConfig({
  testDir: './tests/e2e',
  fullyParallel: true,
  forbidOnly: !!process.env.CI,
  retries: process.env.CI ? 2 : 0,
  workers: process.env.CI ? 1 : undefined,
  reporter: [
    ['html'],
    ['json', { outputFile: 'test-results/e2e-results.json' }],
    ['junit', { outputFile: 'test-results/e2e-junit.xml' }],
  ],
  use: {
    baseURL: process.env.PLAYWRIGHT_BASE_URL || 'http://localhost:3000',
    trace: 'on-first-retry',
    screenshot: 'only-on-failure',
    video: 'retain-on-failure',
  },
  projects: [
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'] },
    },
    {
      name: 'firefox',
      use: { ...devices['Desktop Firefox'] },
    },
    {
      name: 'webkit',
      use: { ...devices['Desktop Safari'] },
    },
    {
      name: 'Mobile Chrome',
      use: { ...devices['Pixel 5'] },
    },
  ],
  webServer: {
    command: 'pnpm dev',
    url: 'http://localhost:3000',
    reuseExistingServer: !process.env.CI,
    stdout: 'pipe',
    stderr: 'pipe',
  },
});
```
````

### API ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— (pytest)

#### backend/tests/conftest.py

```python
import pytest
import asyncio
from typing import AsyncGenerator
from httpx import AsyncClient
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from testcontainers.redis import RedisContainer
from testcontainers.compose import DockerCompose

from src.main import app
from src.infrastructure.database import get_db
from src.domain.events import EventBus

@pytest.fixture(scope="session")
def event_loop():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã§ä½¿ç”¨ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture(scope="session")
async def test_db():
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"""
    engine = create_async_engine(
        "sqlite+aiosqlite:///:memory:",
        echo=False,
    )
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

    yield engine

    await engine.dispose()

@pytest.fixture
async def db_session(test_db) -> AsyncGenerator[AsyncSession, None]:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³"""
    async with AsyncSession(test_db) as session:
        yield session
        await session.rollback()

@pytest.fixture
async def client(db_session) -> AsyncGenerator[AsyncClient, None]:
    """ãƒ†ã‚¹ãƒˆç”¨HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    app.dependency_overrides[get_db] = lambda: db_session

    async with AsyncClient(
        app=app,
        base_url="http://test",
        headers={"X-Test-Client": "true"}
    ) as ac:
        yield ac

    app.dependency_overrides.clear()

@pytest.fixture(scope="session")
def redis():
    """ãƒ†ã‚¹ãƒˆç”¨Redisã‚³ãƒ³ãƒ†ãƒŠ"""
    with RedisContainer() as redis:
        yield redis.get_client()

@pytest.fixture(scope="session")
def docker_compose():
    """çµ±åˆãƒ†ã‚¹ãƒˆç”¨Docker Composeç’°å¢ƒ"""
    compose = DockerCompose(
        "../",
        compose_file_name="docker-compose.test.yml",
        pull=True,
    )
    compose.start()
    compose.wait_for("http://localhost:8000/health")
    yield compose
    compose.stop()
```

### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ (Jest)

#### frontend/jest.config.js

```javascript
const nextJest = require('next/jest');

const createJestConfig = nextJest({
  dir: './',
});

const customJestConfig = {
  setupFilesAfterEnv: ['<rootDir>/jest.setup.js'],
  testEnvironment: 'jest-environment-jsdom',
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/src/$1',
    '^@/components/(.*)$': '<rootDir>/src/components/$1',
  },
  coverageDirectory: 'coverage',
  collectCoverageFrom: [
    'src/**/*.{js,jsx,ts,tsx}',
    '!src/**/*.d.ts',
    '!src/**/*.stories.{js,jsx,ts,tsx}',
    '!src/**/_*.{js,jsx,ts,tsx}',
  ],
  testMatch: [
    '<rootDir>/src/**/__tests__/**/*.{js,jsx,ts,tsx}',
    '<rootDir>/src/**/*.{spec,test}.{js,jsx,ts,tsx}',
  ],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80,
    },
  },
};

module.exports = createJestConfig(customJestConfig);
```

## æ¤œè¨¼é …ç›®

1. âœ… Playwright ã§ã®ãƒãƒ«ãƒãƒ–ãƒ©ã‚¦ã‚¶ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
2. âœ… pytest ã§ã® API ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
3. âœ… Jest ã§ã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
4. âœ… ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
5. âœ… Docker Compose ã§ã®çµ±åˆãƒ†ã‚¹ãƒˆç’°å¢ƒèµ·å‹•

````

---

## ğŸ”§ Step 6.2: CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ï¼ˆç¶šãï¼‰

### ã‚³ãƒãƒ³ãƒ‰

```bash
/ai:operations:deploy pipeline --github-actions --cloudflare --strategy canary --rollback auto
````

### **èµ·å‹•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**

Phase 6 Step 6.2ã§èµ·å‹•ã•ã‚Œã‚‹ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼š

- **devops-coordinator Agent** (ãƒªãƒ¼ãƒ€ãƒ¼): CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®è¨­è¨ˆã¨çµ±æ‹¬
- **test-automation-engineer Agent**: è‡ªå‹•ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã¨ãƒ†ã‚¹ãƒˆã‚¹ãƒ†ãƒƒãƒ—ã®è¨­è¨ˆ
- **security-architect Agent**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚²ãƒ¼ãƒˆã®è¨­å®š
- **version-control-specialist Agent**: ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ã¨ãƒãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ«ã®è¨­å®š
- **observability-engineer Agent**: CI/CDãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ç›£è¦–ã®è¨­å®š

### AI ã¸ã®è©³ç´°æŒ‡ç¤º

```markdown
# CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

GitHub Actions + Cloudflare ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

#### .github/workflows/ci.yml

name: CI Pipeline

on: push: branches: [main, develop] pull_request: branches: [main, develop]

env: PYTHON_VERSION: '3.13' NODE_VERSION: '20' PNPM_VERSION: '8'

jobs: lint-backend: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 -
uses: actions/setup-python@v5 with: python-version: ${{ env.PYTHON_VERSION }} -
name: Install dependencies run: | cd backend pip install -e .[dev] - name: Run
ruff run: | cd backend ruff check src/ - name: Run mypy run: | cd backend mypy
src/ --strict

lint-frontend: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - uses:
pnpm/action-setup@v2 with: version: ${{ env.PNPM_VERSION }} - uses:
actions/setup-node@v4 with: node-version: ${{ env.NODE_VERSION }} cache:
'pnpm' - name: Install dependencies run: | cd frontend pnpm install - name: Run
ESLint run: | cd frontend pnpm lint - name: Type check run: | cd frontend pnpm
type-check

test-backend: runs-on: ubuntu-latest needs: lint-backend steps: - uses:
actions/checkout@v4 - uses: actions/setup-python@v5 with: python-version:
${{ env.PYTHON_VERSION }} - name: Install dependencies run: | cd backend pip
install -e .[dev] - name: Run tests with coverage run: | cd backend pytest
--cov=src --cov-report=xml --cov-fail-under=80 - name: Upload coverage to
Codecov uses: codecov/codecov-action@v3 with: files: ./backend/coverage.xml
flags: backend

test-frontend: runs-on: ubuntu-latest needs: lint-frontend steps: - uses:
actions/checkout@v4 - uses: pnpm/action-setup@v2 with: version:
${{ env.PNPM_VERSION }} - uses: actions/setup-node@v4 with: node-version:
${{ env.NODE_VERSION }} cache: 'pnpm' - name: Install dependencies run: | cd
frontend pnpm install - name: Run tests with coverage run: | cd frontend pnpm
test:ci --coverage - name: Upload coverage to Codecov uses:
codecov/codecov-action@v3 with: files: ./frontend/coverage/lcov.info flags:
frontend

e2e-tests: runs-on: ubuntu-latest needs: [test-backend, test-frontend] steps: -
uses: actions/checkout@v4 - uses: pnpm/action-setup@v2 with: version:
${{ env.PNPM_VERSION }} - uses: actions/setup-node@v4 with: node-version:
${{ env.NODE_VERSION }} - name: Install Playwright run: npx playwright install
--with-deps - name: Run E2E tests run: npx playwright test - uses:
actions/upload-artifact@v3 if: always() with: name: playwright-report path:
playwright-report/ retention-days: 30

security-scan: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name:
Run Trivy vulnerability scanner uses: aquasecurity/trivy-action@master with:
scan-type: 'fs' scan-ref: '.' format: 'sarif' output: 'trivy-results.sarif' -
name: Upload Trivy results to GitHub Security uses:
github/codeql-action/upload-sarif@v2 with: sarif_file: 'trivy-results.sarif'

### ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

#### .github/workflows/deploy.yml

name: Deploy to Cloudflare

on: push: branches: [main] workflow_dispatch:

jobs: deploy-backend: runs-on: ubuntu-latest if: github.ref == 'refs/heads/main'
steps: - uses: actions/checkout@v4 - name: Deploy to Cloudflare Workers uses:
cloudflare/wrangler-action@v3 with: apiToken:
${{ secrets.CLOUDFLARE_API_TOKEN }} workingDirectory: 'backend' command: deploy

deploy-frontend: runs-on: ubuntu-latest if: github.ref == 'refs/heads/main'
steps: - uses: actions/checkout@v4 - uses: pnpm/action-setup@v2 with: version:
8 - uses: actions/setup-node@v4 with: node-version: '20' cache: 'pnpm' - name:
Build frontend run: | cd frontend pnpm install pnpm build - name: Deploy to
Cloudflare Pages uses: cloudflare/pages-action@v1 with: apiToken:
${{ secrets.CLOUDFLARE_API_TOKEN }} accountId:
${{ secrets.CLOUDFLARE_ACCOUNT_ID }} projectName: 'autoforge-nexus' directory:
'frontend/out'

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- å®Œå…¨ãª CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- è‡ªå‹•ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
- Cloudflare è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤
- ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆ
```

### æ¤œè¨¼æ–¹æ³•

```bash
# GitHub Actionsç¢ºèª
gh workflow list
gh workflow run ci.yml
gh run watch

# Cloudflareè¨­å®šç¢ºèª
wrangler whoami
wrangler pages project list
```

---

## ğŸ”§ Step 6.3: å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸

### ã‚³ãƒãƒ³ãƒ‰

```bash
/ai:quality:analyze metrics --coverage 80 --complexity 10 --sonarqube
```

### **èµ·å‹•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**

Phase 6 Step 6.3 ã§èµ·å‹•ã•ã‚Œã‚‹ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼š

- **quality-engineer Agent** (ãƒªãƒ¼ãƒ€ãƒ¼): å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹æˆ¦ç•¥å…¨ä½“ã®è¨­è¨ˆã¨å®Ÿè£…
- **performance-optimizer
  Agent**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã®è¨­å®š
- **security-engineer Agent**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨è„†å¼±æ€§åˆ†æã®è¨­å®š
- **technical-documentation
  Agent**: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è‡ªå‹•ç”Ÿæˆ
- **data-analyst Agent**: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã¨æ´å¯Ÿã®æä¾›

### AI ã¸ã®è©³ç´°æŒ‡ç¤º

```markdown
# å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨­å®šæŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ 80%+ã€å¾ªç’°è¤‡é›‘åº¦ 10 ä»¥ä¸‹ã‚’ç›®æ¨™ã¨ã™ã‚‹å“è³ªç®¡ç†ä½“åˆ¶ã®æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### SonarQube è¨­å®š

#### sonar-project.properties

sonar.projectKey=autoforge-nexus sonar.organization=autoforge
sonar.sources=backend/src,frontend/src sonar.tests=backend/tests,frontend/tests
sonar.python.coverage.reportPaths=backend/coverage.xml
sonar.javascript.lcov.reportPaths=frontend/coverage/lcov.info
sonar.python.version=3.13
sonar.exclusions=**/\*.test.ts,**/\*.spec.py,**/migrations/**

### å“è³ªã‚²ãƒ¼ãƒˆè¨­å®š

#### .github/quality-gates.yml

quality_gates: coverage: backend: 80 frontend: 75 complexity: max_cyclomatic: 10
max_cognitive: 15 duplications: max_percentage: 3 security_hotspots: 0
code_smells: max_count: 10 max_debt: 1d

### pytest ã‚«ãƒãƒ¬ãƒƒã‚¸è¨­å®š

#### backend/.coveragerc

[run] source = src omit = _/tests/_ _/migrations/_ _/**init**.py _/conftest.py

[report] precision = 2 show_missing = True skip_covered = True fail_under = 80

[html] directory = htmlcov

### Jest ã‚«ãƒãƒ¬ãƒƒã‚¸è¨­å®š

#### frontend/jest.coverage.config.js

module.exports = { collectCoverage: true, collectCoverageFrom: [
'src/**/*.{ts,tsx}', '!src/**/*.d.ts', '!src/**/*.stories.tsx',
'!src/**/index.ts', ], coverageDirectory: 'coverage', coverageReporters:
['text', 'lcov', 'html'], coverageThreshold: { global: { branches: 75,
functions: 75, lines: 75, statements: 75, }, }, };

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- SonarQube çµ±åˆ
- å“è³ªã‚²ãƒ¼ãƒˆè¨­å®š
- ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ
- è¤‡é›‘åº¦åˆ†æ
- æŠ€è¡“çš„è² å‚µè¿½è·¡
```

### æ¤œè¨¼æ–¹æ³•

```bash
# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸
cd backend
pytest --cov=src --cov-report=html
open htmlcov/index.html

# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸
cd frontend
pnpm test:coverage
open coverage/index.html

# SonarQubeåˆ†æ
sonar-scanner
```

---

## ğŸ”§ Step 6.4: ç›£è¦–ãƒ»ãƒ­ã‚°åé›†ã‚·ã‚¹ãƒ†ãƒ 

### ã‚³ãƒãƒ³ãƒ‰

```bash
/ai:operations:monitor observability --langfuse --prometheus --grafana --loki
```

### **èµ·å‹•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**

Phase 6 Step 6.4 ã§èµ·å‹•ã•ã‚Œã‚‹ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼š

- **observability-engineer Agent** (ãƒªãƒ¼ãƒ€ãƒ¼): ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®è¨­è¨ˆã¨å®Ÿè£…
- **sre-agent-agent Agent**: SLO/SLI å®šç¾©ã¨ã‚¢ãƒ©ãƒ¼ãƒˆæˆ¦ç•¥ã®è¨­è¨ˆ
- **performance-engineer Agent**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ APM è¨­å®š
- **llm-integration Agent**: LangFuse ã¨ LLM ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®è¨­å®š
- **edge-computing-specialist Agent**: Cloudflare Analytics ã¨ã‚¨ãƒƒã‚¸ç›£è¦–ã®è¨­å®š

### AI ã¸ã®è©³ç´°æŒ‡ç¤º

```markdown
# ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

LangFuse + Prometheus + Grafana + Loki ã«ã‚ˆã‚‹åŒ…æ‹¬çš„ç›£è¦–ä½“åˆ¶ã®æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### Docker Compose ç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯

#### docker-compose.monitoring.yml

version: '3.8'

services: prometheus: image: prom/prometheus:latest volumes: -
./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml -
prometheus_data:/prometheus ports: - "9090:9090" command: -
'--config.file=/etc/prometheus/prometheus.yml' -
'--storage.tsdb.path=/prometheus'

grafana: image: grafana/grafana:latest volumes: -
grafana_data:/var/lib/grafana -
./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards -
./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
environment: - GF_SECURITY_ADMIN_PASSWORD=admin -
GF_INSTALL_PLUGINS=grafana-piechart-panel ports: - "3001:3000"

loki: image: grafana/loki:latest ports: - "3100:3100" volumes: -
./monitoring/loki-config.yaml:/etc/loki/local-config.yaml - loki_data:/loki

promtail: image: grafana/promtail:latest volumes: -
./monitoring/promtail-config.yaml:/etc/promtail/config.yml - /var/log:/var/log
command: -config.file=/etc/promtail/config.yml

langfuse: image: langfuse/langfuse:latest environment: -
DATABASE_URL=postgresql://langfuse:password@postgres:5432/langfuse -
NEXTAUTH_SECRET=${{ secrets.NEXTAUTH_SECRET }}
      - SALT=${{ secrets.SALT }} ports: - "3002:3000" depends_on: - postgres

postgres: image: postgres:16 environment: - POSTGRES_DB=langfuse -
POSTGRES_USER=langfuse - POSTGRES_PASSWORD=password volumes: -
postgres_data:/var/lib/postgresql/data

volumes: prometheus_data: grafana_data: loki_data: postgres_data:

### Prometheus è¨­å®š

#### monitoring/prometheus.yml

global: scrape_interval: 15s evaluation_interval: 15s

scrape_configs:

- job_name: 'backend' static_configs:

  - targets: ['backend:8000'] metrics_path: '/metrics'

- job_name: 'frontend' static_configs:

  - targets: ['frontend:3000'] metrics_path: '/api/metrics'

- job_name: 'node-exporter' static_configs:
  - targets: ['node-exporter:9100']

### LangFuse çµ±åˆ

#### backend/src/infrastructure/langfuse_config.py

from langfuse import Langfuse from langfuse.decorators import observe import os

langfuse = Langfuse( public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
secret_key=os.getenv("LANGFUSE_SECRET_KEY"), host=os.getenv("LANGFUSE_HOST",
"http://localhost:3002") )

@observe() async def track_llm_call( prompt: str, model: str, response: str,
latency: float, cost: float ): """LLM å‘¼ã³å‡ºã—ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°""" langfuse.trace(
name="llm_call", input=prompt, output=response, metadata={ "model": model,
"latency_ms": latency \* 1000, "cost_usd": cost } )

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- çµ±åˆç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†è¨­å®š
- ãƒ­ã‚°é›†ç´„ã‚·ã‚¹ãƒ†ãƒ 
- LLM ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š
```

### æ¤œè¨¼æ–¹æ³•

```bash
# ç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯èµ·å‹•
docker-compose -f docker-compose.monitoring.yml up -d

# ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
open http://localhost:9090  # Prometheus
open http://localhost:3001  # Grafana (admin/admin)
open http://localhost:3002  # LangFuse
```

---

## ğŸ”§ Step 6.5: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹

### ã‚³ãƒãƒ³ãƒ‰

```bash
/ai:quality:security scan --owasp --gdpr --trivy --snyk
```

### **èµ·å‹•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**

Phase 6 Step 6.5 ã§èµ·å‹•ã•ã‚Œã‚‹ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼š

- **security-architect Agent**
  (ãƒªãƒ¼ãƒ€ãƒ¼): ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å…¨ä½“ã®è¨­è¨ˆã¨å®Ÿè£…
- **compliance-officer Agent**: GDPR/CCPA ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶ã®å®Ÿè£…
- **security-engineer Agent**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ãƒ„ãƒ¼ãƒ«ã¨è„†å¼±æ€§ç®¡ç†ã®è¨­å®š
- **backend-architect Agent**: ã‚»ã‚­ãƒ¥ã‚¢ãª API ã¨ãƒ‡ãƒ¼ã‚¿ä¿è­·ã®å®Ÿè£…
- **devops-architect Agent**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ã‚¤ãƒ³ãƒ•ãƒ©ä¿è­·ã®è¨­å®š

### AI ã¸ã®è©³ç´°æŒ‡ç¤º

```markdown
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šæŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

OWASP Top 10 å¯¾ç­–ã€GDPR æº–æ‹ ã€è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ã®å®Œå…¨å®Ÿè£…

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³è¨­å®š

#### .github/workflows/security.yml

name: Security Scan

on: push: branches: [main, develop] schedule: - cron: '0 0 \* \* \*' # æ¯æ—¥å®Ÿè¡Œ

jobs: trivy-scan: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 -
name: Run Trivy vulnerability scanner in repo mode uses:
aquasecurity/trivy-action@master with: scan-type: 'fs' ignore-unfixed: true
format: 'sarif' output: 'trivy-results.sarif' severity: 'CRITICAL,HIGH'

snyk-scan: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Run
Snyk to check for vulnerabilities uses: snyk/actions/python@master env:
SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }} with: args: --severity-threshold=high

owasp-zap: runs-on: ubuntu-latest steps: - name: OWASP ZAP Baseline Scan uses:
zaproxy/action-baseline@v0.9.0 with: target: 'http://localhost:3000'
rules_file_name: '.zap/rules.tsv' cmd_options: '-a'

### ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæ¤œå‡º

#### .gitleaks.toml

[allowlist] paths = [ '''\.env\.example''', '''\.env\.template''', ]

[[rules]] id = "aws-access-key" description = "AWS Access Key" regex =
'''(?i)aws*?access*?key\_?id["']?\s*[:=]\s*["']?[A-Z0-9]{20}["']?'''

[[rules]] id = "private-key" description = "Private Key" regex = '''-----BEGIN
(?:RSA |EC |DSA |OPENSSH )?PRIVATE KEY-----'''

### GDPR ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹

#### backend/src/infrastructure/gdpr/data_protection.py

from typing import Dict, Any, List import hashlib from datetime import datetime

class DataProtectionService: """GDPR æº–æ‹ ã®ãƒ‡ãƒ¼ã‚¿ä¿è­·ã‚µãƒ¼ãƒ“ã‚¹"""

    async def anonymize_user_data(self, user_id: str) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®åŒ¿ååŒ–"""
        # PIIï¼ˆå€‹äººè­˜åˆ¥æƒ…å ±ï¼‰ã‚’ãƒãƒƒã‚·ãƒ¥åŒ–
        return {
            "user_id": hashlib.sha256(user_id.encode()).hexdigest(),
            "anonymized_at": datetime.utcnow(),
            "data_retained": ["usage_stats", "preferences"],
            "data_deleted": ["email", "name", "phone"]
        }

    async def export_user_data(self, user_id: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ“ãƒªãƒ†ã‚£å¯¾å¿œ"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        return {
            "user_profile": {},
            "prompts": [],
            "evaluations": [],
            "exported_at": datetime.utcnow()
        }

    async def delete_user_data(self, user_id: str) -> bool:
        """å¿˜ã‚Œã‚‰ã‚Œã‚‹æ¨©åˆ©ã®å®Ÿè£…"""
        # å®Œå…¨å‰Šé™¤å‡¦ç†
        return True

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š

#### frontend/next.config.js

const securityHeaders = [ { key: 'X-DNS-Prefetch-Control', value: 'on' }, { key:
'Strict-Transport-Security', value: 'max-age=63072000; includeSubDomains;
preload' }, { key: 'X-Frame-Options', value: 'SAMEORIGIN' }, { key:
'X-Content-Type-Options', value: 'nosniff' }, { key: 'X-XSS-Protection', value:
'1; mode=block' }, { key: 'Referrer-Policy', value: 'origin-when-cross-origin'
}, { key: 'Content-Security-Policy', value: "default-src 'self'; script-src
'self' 'unsafe-eval' 'unsafe-inline';" } ]

module.exports = { async headers() { return [ { source: '/:path*', headers:
securityHeaders, }, ] }, }

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- è‡ªå‹•ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
- OWASP Top 10 å¯¾ç­–
- GDPR æº–æ‹ æ©Ÿèƒ½
- ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæ¤œå‡º
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼
```

### æ¤œè¨¼æ–¹æ³•

```bash
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ
trivy fs .
snyk test
gitleaks detect

# OWASP ZAPã‚¹ã‚­ãƒ£ãƒ³
docker run -t owasp/zap2docker-stable zap-baseline.py -t http://localhost:3000
```

---

## ğŸ”§ Step 6.6: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç’°å¢ƒ

### ã‚³ãƒãƒ³ãƒ‰

```bash
/ai:performance-engineer load-test --locust --k6 --target 10000
```

### **èµ·å‹•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**

Phase 6 Step 6.6 ã§èµ·å‹•ã•ã‚Œã‚‹ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼š

- **performance-engineer Agent**
  (ãƒªãƒ¼ãƒ€ãƒ¼): ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆæˆ¦ç•¥å…¨ä½“ã®è¨­è¨ˆã¨å®Ÿè£…
- **real-time-features-specialist Agent**:
  WebSocket ã¨ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ©Ÿèƒ½ã®è² è·ãƒ†ã‚¹ãƒˆ
- **edge-database-administrator
  Agent**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã¨æœ€é©åŒ–
- **vector-database-specialist Agent**: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æ¸¬å®šã¨æœ€é©åŒ–
- **cost-optimization Agent**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å¯¾ã‚³ã‚¹ãƒˆåˆ†æã¨ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–

### AI ã¸ã®è©³ç´°æŒ‡ç¤º

```markdown
# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç’°å¢ƒæ§‹ç¯‰æŒ‡ç¤º

## å®Ÿè¡Œå†…å®¹

10,000 åŒæ™‚æ¥ç¶šã‚’ç›®æ¨™ã¨ã™ã‚‹è² è·ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ§‹ç¯‰

## å…·ä½“çš„ãªä½œæ¥­é …ç›®

### Locust è¨­å®š

#### tests/performance/locustfile.py

from locust import HttpUser, task, between import random

class AutoForgeUser(HttpUser): wait_time = between(1, 3)

    def on_start(self):
        # ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†
        self.client.post("/api/auth/login", json={
            "email": f"test_{random.randint(1, 10000)}@example.com",
            "password": "password123"
        })

    @task(3)
    def create_prompt(self):
        self.client.post("/api/v1/prompts", json={
            "title": f"Test Prompt {random.randint(1, 1000)}",
            "content": "This is a test prompt for load testing",
            "description": "Load test description"
        })

    @task(2)
    def get_prompts(self):
        self.client.get("/api/v1/prompts")

    @task(1)
    def search_prompts(self):
        self.client.get(f"/api/v1/prompts/search?q=test")

### K6 ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª

#### tests/performance/k6-scenario.js

import http from 'k6/http'; import { check, sleep } from 'k6'; import { Rate }
from 'k6/metrics';

const errorRate = new Rate('errors');

export const options = { stages: [ { duration: '2m', target: 100 }, //
ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ— { duration: '5m', target: 1000 }, // ç¶­æŒ { duration: '2m', target:
10000 }, // ã‚¹ãƒ‘ã‚¤ã‚¯ { duration: '5m', target: 10000 }, // é«˜è² è·ç¶­æŒ {
duration: '2m', target: 0 }, // ãƒ©ãƒ³ãƒ—ãƒ€ã‚¦ãƒ³ ], thresholds: { http_req_duration:
['p(95)<200'], // 95% < 200ms errors: ['rate<0.1'], // ã‚¨ãƒ©ãƒ¼ç‡ < 10% }, };

export default function () { const url = 'http://localhost:8000/api/v1/prompts';
const params = { headers: { 'Content-Type': 'application/json', }, };

const res = http.get(url, params);

const success = check(res, { 'status is 200': (r) => r.status === 200, 'response
time < 200ms': (r) => r.timings.duration < 200, });

errorRate.add(!success); sleep(1); }

### WebSocket è² è·ãƒ†ã‚¹ãƒˆ

#### tests/performance/websocket_test.py

import asyncio import websockets import json from datetime import datetime

async def websocket_client(client_id: int): uri = "ws://localhost:8000/ws" async
with websockets.connect(uri) as websocket: # æ¥ç¶šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ await
websocket.send(json.dumps({ "type": "connect", "client_id": client_id,
"timestamp": datetime.utcnow().isoformat() }))

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å”èª¿ç·¨é›†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        for i in range(100):
            await websocket.send(json.dumps({
                "type": "edit",
                "content": f"Edit from client {client_id} - {i}",
                "timestamp": datetime.utcnow().isoformat()
            }))
            await asyncio.sleep(0.1)

async def load_test(num_clients: int = 10000): tasks = [] for i in
range(num_clients): tasks.append(websocket_client(i)) if i % 100 == 0: await
asyncio.sleep(0.1) # æ®µéšçš„æ¥ç¶š

    await asyncio.gather(*tasks)

if **name** == "**main**": asyncio.run(load_test())

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### Makefile

.PHONY: perf-test perf-locust perf-k6 perf-websocket

perf-locust: @echo "ğŸ”¥ Starting Locust load test..." locust -f
tests/performance/locustfile.py \
 --host=http://localhost:8000 \
 --users=1000 \
 --spawn-rate=50 \
 --run-time=10m \
 --headless

perf-k6: @echo "ğŸ“Š Starting K6 performance test..." k6 run
tests/performance/k6-scenario.js

perf-websocket: @echo "ğŸŒ Starting WebSocket load test..." python
tests/performance/websocket_test.py

perf-test: perf-locust perf-k6 perf-websocket @echo "âœ… All performance tests
completed"

perf-report: @echo "ğŸ“ˆ Generating performance report..." python
scripts/generate_perf_report.py

## æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

- Locust è² è·ãƒ†ã‚¹ãƒˆè¨­å®š
- K6 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- WebSocket åŒæ™‚æ¥ç¶šãƒ†ã‚¹ãƒˆ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- 10,000 åŒæ™‚æ¥ç¶šé”æˆ
```

### æ¤œè¨¼æ–¹æ³•

```bash
# Locust Web UIèµ·å‹•
locust -f tests/performance/locustfile.py --host=http://localhost:8000

# K6ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
k6 run tests/performance/k6-scenario.js

# WebSocketãƒ†ã‚¹ãƒˆ
python tests/performance/websocket_test.py

# çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
make perf-test
```

---

## ğŸ“ Phase 6 å®Œäº†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### âœ… å¿…é ˆé …ç›®

- [ ] **çµ±åˆãƒ†ã‚¹ãƒˆç’°å¢ƒ**

  - [ ] Playwright E2E ãƒ†ã‚¹ãƒˆè¨­å®šå®Œäº†
  - [ ] pytest API çµ±åˆãƒ†ã‚¹ãƒˆè¨­å®šå®Œäº†
  - [ ] Jest ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆè¨­å®šå®Œäº†
  - [ ] Docker Compose ãƒ†ã‚¹ãƒˆç’°å¢ƒæ§‹ç¯‰å®Œäº†

- [ ] **CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**

  - [ ] GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­å®šå®Œäº†
  - [ ] Cloudflare ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆè¨­å®šå®Œäº†
  - [ ] å“è³ªã‚²ãƒ¼ãƒˆè¨­å®šå®Œäº†
  - [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆå®Œäº†

- [ ] **å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹**

  - [ ] ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ 80%ä»¥ä¸Š
  - [ ] ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ 75%ä»¥ä¸Š
  - [ ] SonarQube çµ±åˆå®Œäº†
  - [ ] å¾ªç’°è¤‡é›‘åº¦ 10 ä»¥ä¸‹

- [ ] **ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ **

  - [ ] Prometheus + Grafana è¨­å®šå®Œäº†
  - [ ] LangFuse LLM ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°è¨­å®šå®Œäº†
  - [ ] Loki ãƒ­ã‚°é›†ç´„è¨­å®šå®Œäº†
  - [ ] ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šå®Œäº†

- [ ] **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**

  - [ ] OWASP Top 10 å¯¾ç­–å®Ÿè£…
  - [ ] GDPR æº–æ‹ æ©Ÿèƒ½å®Ÿè£…
  - [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³è‡ªå‹•åŒ–
  - [ ] ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæ¤œå‡ºè¨­å®š

- [ ] **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**
  - [ ] API å¿œç­”æ™‚é–“ P95 < 200ms
  - [ ] WebSocket 10,000 åŒæ™‚æ¥ç¶šé”æˆ
  - [ ] è² è·ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªä½œæˆå®Œäº†
  - [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

Phase 6 å®Œäº†å¾Œã¯ã€ä»¥ä¸‹ã®ä½œæ¥­ã«é€²ã¿ã¾ã™ï¼š

1. **æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤æº–å‚™**

   - ç’°å¢ƒå¤‰æ•°ã®æœ€çµ‚ç¢ºèª
   - ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†ã®è¨­å®š
   - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ãƒªã‚«ãƒãƒªæ‰‹é †ã®ç¢ºç«‹

2. **ãƒ¦ãƒ¼ã‚¶ãƒ¼å—ã‘å…¥ã‚Œãƒ†ã‚¹ãƒˆï¼ˆUATï¼‰**

   - ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã«ã‚ˆã‚‹æ¤œè¨¼
   - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†ã¨å¯¾å¿œ

3. **æœ¬ç•ªãƒªãƒªãƒ¼ã‚¹**

   - æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ
   - ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°å¼·åŒ–
   - ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œä½“åˆ¶ç¢ºç«‹

4. **ç¶™ç¶šçš„æ”¹å–„**
   - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
   - æ©Ÿèƒ½è¿½åŠ ãƒ»æ”¹å–„
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¯¾å¿œ
