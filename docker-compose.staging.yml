# ==========================================
# Staging Docker Compose Configuration
# ==========================================
# Phase 4: Database Vector Setup - Staging Environment

services:
  # ===================
  # Backend API Service
  # ===================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.staging
    container_name: autoforge-backend-staging
    ports:
      - "8001:8000"
    environment:
      - APP_ENV=staging
      - HOST=0.0.0.0
      - PORT=8000
      # Turso Staging Database
      - TURSO_DATABASE_URL=${TURSO_STAGING_DATABASE_URL}
      - TURSO_AUTH_TOKEN=${TURSO_STAGING_AUTH_TOKEN}
      # Redis Staging
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_STAGING_PASSWORD}
      - REDIS_DB=1
      # Debug settings for staging
      - DEBUG=true
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
      # Clerk Authentication (Staging)
      - CLERK_SECRET_KEY=${CLERK_STAGING_SECRET_KEY}
      - CLERK_PUBLIC_KEY=${CLERK_STAGING_PUBLIC_KEY}
      # LLM Providers (Staging - Rate Limited)
      - OPENAI_API_KEY=${OPENAI_STAGING_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_STAGING_API_KEY}
      # JWT
      - JWT_SECRET_KEY=${JWT_STAGING_SECRET_KEY}
      - JWT_ALGORITHM=HS256
      - JWT_EXPIRATION_MINUTES=120
    volumes:
      - backend-staging-data:/app/data
      - backend-staging-logs:/app/logs
      - ./backend:/app:ro  # Read-only mount for code updates
    depends_on:
      redis:
        condition: service_healthy
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 2
    networks:
      - autoforge-staging-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ===================
  # Frontend Service
  # ===================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.staging
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_STAGING_API_URL}
        - NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_STAGING_WS_URL}
        - NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=${NEXT_PUBLIC_CLERK_STAGING_KEY}
    container_name: autoforge-frontend-staging
    ports:
      - "3001:3000"
    environment:
      - NODE_ENV=staging
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_STAGING_API_URL}
      - NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_STAGING_WS_URL}
      - NEXT_PUBLIC_API_BASE_URL=${NEXT_PUBLIC_STAGING_API_BASE_URL}
      - NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=${NEXT_PUBLIC_CLERK_STAGING_KEY}
      - CLERK_SECRET_KEY=${CLERK_STAGING_SECRET_KEY}
      # Enable error reporting in staging
      - NEXT_PUBLIC_SENTRY_DSN=${SENTRY_STAGING_DSN}
    volumes:
      - ./frontend:/app:ro  # Read-only mount for code inspection
    depends_on:
      backend:
        condition: service_healthy
    command: pnpm start
    networks:
      - autoforge-staging-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ===================
  # Redis Cache Service (Staging)
  # ===================
  redis:
    image: redis:7.4-alpine
    container_name: autoforge-redis-staging
    ports:
      - "6380:6379"
    volumes:
      - redis-staging-data:/data
    command: redis-server --appendonly yes --requirepass ${REDIS_STAGING_PASSWORD}
    networks:
      - autoforge-staging-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "${REDIS_STAGING_PASSWORD}", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # ===================
  # Test Database Seeder (Staging Only)
  # ===================
  db-seeder:
    build:
      context: ./backend
      dockerfile: Dockerfile.seeder
    container_name: autoforge-seeder-staging
    environment:
      - APP_ENV=staging
      - TURSO_DATABASE_URL=${TURSO_STAGING_DATABASE_URL}
      - TURSO_AUTH_TOKEN=${TURSO_STAGING_AUTH_TOKEN}
    volumes:
      - ./backend/scripts:/scripts
    command: python /scripts/seed_staging_data.py
    networks:
      - autoforge-staging-network
    depends_on:
      - backend
    restart: "no"

  # ===================
  # Monitoring Stack (Staging)
  # ===================
  prometheus:
    image: prom/prometheus:latest
    container_name: autoforge-prometheus-staging
    ports:
      - "9091:9090"
    volumes:
      - ./monitoring/prometheus.staging.yml:/etc/prometheus/prometheus.yml
      - prometheus-staging-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
    networks:
      - autoforge-staging-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: autoforge-grafana-staging
    ports:
      - "3003:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_STAGING_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_STAGING_PASSWORD}
      - GF_INSTALL_PLUGINS=redis-datasource
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
    volumes:
      - grafana-staging-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    depends_on:
      - prometheus
    networks:
      - autoforge-staging-network
    restart: unless-stopped

  # ===================
  # Test Runner (Staging E2E Tests)
  # ===================
  e2e-tests:
    build:
      context: ./frontend
      dockerfile: Dockerfile.e2e
    container_name: autoforge-e2e-staging
    environment:
      - BASE_URL=http://frontend:3000
      - API_URL=http://backend:8000
      - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
    volumes:
      - ./frontend/tests:/tests
      - e2e-results:/results
    depends_on:
      - frontend
      - backend
    command: pnpm test:e2e:staging
    networks:
      - autoforge-staging-network
    restart: "no"

# ===================
# Networks
# ===================
networks:
  autoforge-staging-network:
    driver: bridge
    name: autoforge-network-staging

# ===================
# Volumes
# ===================
volumes:
  backend-staging-data:
    name: autoforge-backend-data-staging
  backend-staging-logs:
    name: autoforge-backend-logs-staging
  redis-staging-data:
    name: autoforge-redis-data-staging
  prometheus-staging-data:
    name: autoforge-prometheus-data-staging
  grafana-staging-data:
    name: autoforge-grafana-data-staging
  e2e-results:
    name: autoforge-e2e-results-staging